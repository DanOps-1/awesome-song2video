"""æ„å»ºæ­Œè¯ä¸è§†é¢‘ç‰‡æ®µçš„æ—¶é—´çº¿ã€‚"""

from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Coroutine, Optional, TypedDict
import re
from uuid import uuid4

# è¿›åº¦å›è°ƒç±»å‹: async def callback(progress: float) -> None
ProgressCallback = Callable[[float], Coroutine[Any, Any, None]]

import structlog

from src.infra.config.settings import get_settings
from src.pipelines.lyrics_ingest.transcriber import transcribe_with_timestamps
from src.services.matching.twelvelabs_client import client
from src.services.matching.query_rewriter import QueryRewriter


def calculate_overlap_ratio(start1: int, end1: int, start2: int, end2: int) -> float:
    """è®¡ç®—ä¸¤ä¸ªæ—¶é—´æ®µçš„é‡å æ¯”ä¾‹ã€‚

    è¿”å›: é‡å éƒ¨åˆ†å è¾ƒçŸ­ç‰‡æ®µçš„æ¯”ä¾‹ (0.0 åˆ° 1.0)
    """
    overlap_start = max(start1, start2)
    overlap_end = min(end1, end2)
    overlap = max(0, overlap_end - overlap_start)

    if overlap == 0:
        return 0.0

    duration1 = end1 - start1
    duration2 = end2 - start2
    shorter_duration = min(duration1, duration2)

    if shorter_duration == 0:
        return 0.0

    return overlap / shorter_duration


@dataclass
class TimelineLine:
    text: str
    start_ms: int
    end_ms: int
    candidates: list[dict]


@dataclass
class TimelineResult:
    lines: list[TimelineLine] = field(default_factory=list)


class CandidateWithUsage(TypedDict):
    candidate: dict[str, int | float | str]
    usage_count: int
    score: float


class TimelineBuilder:
    def __init__(self) -> None:
        self._settings = get_settings()
        self._use_mock_segments = not self._settings.tl_live_enabled
        self._candidate_cache: dict[tuple[str, int], list[dict[str, Any]]] = {}
        self._logger = structlog.get_logger(__name__)
        self._split_pattern = re.compile(r"(?:\r?\n)+|[ï¼Œ,ã€‚ï¼ï¼Ÿ!?ï¼›;â€¦]")
        self._rewriter = QueryRewriter()
        # è¿½è¸ªå·²ä½¿ç”¨çš„è§†é¢‘ç‰‡æ®µï¼Œé¿å…é‡å¤
        # key = (video_id, start_ms, end_ms), value = ä½¿ç”¨æ¬¡æ•°
        self._used_segments: dict[tuple[str, int, int], int] = {}
        # é‡å é˜ˆå€¼ï¼šé›¶å®¹å¿ï¼ä»»ä½•é‡å éƒ½ä¸å…è®¸
        self._overlap_threshold = 0.0  # ä»»ä½•é‡å  > 0 å°±è·³è¿‡

    def _is_non_lyric_text(self, text: str) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºéæ­Œè¯å†…å®¹ï¼ˆå¦‚ä½œè¯ã€ä½œæ›²ã€ç¼–æ›²ç­‰æ ‡æ³¨ï¼‰ã€‚

        è¯†åˆ«æ¨¡å¼ï¼š
        - "ä½œè¯ XX" / "è¯ XX"
        - "ä½œæ›² XX" / "æ›² XX"
        - "ç¼–æ›² XX" / "ç¼– XX"
        - "æ¼”å”± XX" / "å”± XX"
        - "åˆ¶ä½œ XX"
        - çº¯è‹±æ–‡çš„ creditsï¼ˆå¦‚ "Lyrics by", "Music by"ï¼‰
        """
        text = text.strip()

        # ä¸­æ–‡ credits æ¨¡å¼
        non_lyric_patterns = [
            r'^ä½œè¯[\s:ï¼š]',
            r'^è¯[\s:ï¼š]',
            r'^ä½œæ›²[\s:ï¼š]',
            r'^æ›²[\s:ï¼š]',
            r'^ç¼–æ›²[\s:ï¼š]',
            r'^ç¼–[\s:ï¼š]',
            r'^æ¼”å”±[\s:ï¼š]',
            r'^å”±[\s:ï¼š]',
            r'^åˆ¶ä½œ[\s:ï¼š]',
            r'^ç›‘åˆ¶[\s:ï¼š]',
            r'^æ··éŸ³[\s:ï¼š]',
            r'^æ¯å¸¦[\s:ï¼š]',
        ]

        # è‹±æ–‡ credits æ¨¡å¼
        english_patterns = [
            r'(?i)^lyrics\s+by',
            r'(?i)^music\s+by',
            r'(?i)^composed\s+by',
            r'(?i)^arranged\s+by',
            r'(?i)^performed\s+by',
            r'(?i)^produced\s+by',
        ]

        all_patterns = non_lyric_patterns + english_patterns

        for pattern in all_patterns:
            if re.search(pattern, text):
                return True

        return False

    def _get_audio_duration(self, audio_path: Path) -> int:
        """ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ã€‚"""
        import subprocess

        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            audio_path.as_posix(),
        ]
        try:
            result = subprocess.run(
                cmd,
                check=False,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=10,
            )
            if result.returncode == 0 and result.stdout.strip():
                return int(float(result.stdout.strip()) * 1000)
        except Exception as exc:
            self._logger.warning("ffprobe.audio_duration_failed", path=audio_path, error=str(exc))
        return 0

    def _split_by_duration(self, segments: list[dict[str, Any]], max_duration: float = 12.0) -> list[dict[str, Any]]:
        """å°†è¿‡é•¿çš„ç‰‡æ®µæŒ‰æ—¶é•¿åˆ‡åˆ†ä¸ºæ›´å°çš„ç‰‡æ®µï¼Œä»¥å¢åŠ ç”»é¢ä¸°å¯Œåº¦ã€‚"""
        split_segments: list[dict[str, Any]] = []
        for seg in segments:
            start = float(seg.get("start", 0))
            end = float(seg.get("end", 0))
            duration = end - start
            
            if duration <= max_duration:
                split_segments.append(seg)
                continue
                
            # è®¡ç®—éœ€è¦åˆ‡åˆ†çš„å—æ•°
            num_chunks = int(duration // max_duration) + 1
            chunk_duration = duration / num_chunks
            
            text = seg.get("text", "")
            base_prompt = seg.get("search_prompt", "")
            
            for i in range(num_chunks):
                chunk_start = start + (i * chunk_duration)
                chunk_end = chunk_start + chunk_duration
                
                # åˆ›å»ºæ–°ç‰‡æ®µï¼Œå¤åˆ¶å…ƒæ•°æ®
                new_seg = seg.copy()
                new_seg["start"] = chunk_start
                new_seg["end"] = chunk_end
                
                # å¦‚æœæœ‰æœç´¢æç¤ºè¯ï¼Œæ·»åŠ å˜åŒ–ä»¥å¢åŠ å¤šæ ·æ€§
                if base_prompt:
                    new_seg["search_prompt"] = f"{base_prompt}, scene {i+1}"
                
                # å¯¹äºé•¿æ–‡æœ¬ï¼ˆå¦‚ Creditsï¼‰ï¼Œåç»­ç‰‡æ®µå¯ä»¥ä¸å†æ˜¾ç¤ºæ–‡æœ¬ï¼Œæˆ–è€…ä¿ç•™
                # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œä¿ç•™æ–‡æœ¬ï¼Œä½†ç”»é¢ä¼šå˜
                
                split_segments.append(new_seg)
                
            self._logger.info(
                "timeline_builder.split_long_segment",
                original_text=text[:20],
                original_duration=round(duration, 2),
                chunks=num_chunks,
                message="é•¿ç‰‡æ®µå·²åˆ‡åˆ†",
            )
            
        return split_segments

    async def transcribe_only(
        self,
        audio_path: Path,
        language: str | None = None,
        prompt: str | None = None,
        on_progress: ProgressCallback | None = None,
    ) -> list[dict[str, Any]]:
        """åªè¿›è¡Œ Whisper è¯†åˆ«ï¼Œè¿”å›æ­Œè¯ç‰‡æ®µåˆ—è¡¨ï¼ˆä¸è¿›è¡Œè§†é¢‘åŒ¹é…ï¼‰ã€‚

        è¿”å›æ ¼å¼: [{"text": "æ­Œè¯", "start": å¼€å§‹ç§’, "end": ç»“æŸç§’}, ...]
        """
        async def report_progress(progress: float) -> None:
            if on_progress:
                await on_progress(progress)

        await report_progress(5.0)  # 5%: å¼€å§‹å¤„ç†éŸ³é¢‘
        audio_duration_ms = self._get_audio_duration(audio_path)
        self._logger.info(
            "timeline_builder.audio_info",
            path=str(audio_path),
            duration_ms=audio_duration_ms
        )
        await report_progress(20.0)  # 20%: å¼€å§‹ Whisper è¯†åˆ«

        raw_segments = await transcribe_with_timestamps(
            audio_path,
            language=language,
            prompt=prompt
        )
        segments = [dict(segment) for segment in raw_segments]

        await report_progress(80.0)  # 80%: Whisper è¯†åˆ«å®Œæˆ

        # åˆ†å‰²é•¿ç‰‡æ®µ
        segments = self._explode_segments(segments)

        await report_progress(100.0)  # 100%: å®Œæˆ
        return segments

    async def match_videos_for_lines(
        self,
        lines: list[dict[str, Any]],
        audio_duration_ms: int = 0,
        on_progress: ProgressCallback | None = None,
    ) -> TimelineResult:
        """å¯¹å·²ç¡®è®¤çš„æ­Œè¯è¡Œè¿›è¡Œè§†é¢‘åŒ¹é…ã€‚

        Args:
            lines: æ­Œè¯è¡Œåˆ—è¡¨ï¼Œæ ¼å¼ [{"text": "...", "start_ms": int, "end_ms": int}, ...]
            audio_duration_ms: éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œç”¨äºå¡«å……å°¾éƒ¨
            on_progress: è¿›åº¦å›è°ƒ
        """
        self._candidate_cache.clear()
        self._used_segments.clear()

        async def report_progress(progress: float) -> None:
            if on_progress:
                await on_progress(progress)

        await report_progress(5.0)

        # è½¬æ¢ä¸ºå†…éƒ¨ segments æ ¼å¼
        segments: list[dict[str, Any]] = []
        for line in lines:
            segments.append({
                "text": line["text"],
                "start": line["start_ms"] / 1000.0,
                "end": line["end_ms"] / 1000.0,
            })

        # æ ‡è®°éæ­Œè¯å†…å®¹
        for seg in segments:
            text = str(seg.get("text", "")).strip()
            start = float(seg.get("start", 0))
            end = float(seg.get("end", 0))
            duration_s = end - start

            if self._is_non_lyric_text(text):
                if duration_s < 10.0:
                    seg["is_non_lyric"] = True
                else:
                    seg["is_non_lyric"] = False
                    seg["search_prompt"] = "cinematic music video intro, atmospheric, slow motion"

        # åˆ‡åˆ†é•¿ç‰‡æ®µ
        segments = self._split_by_duration(segments, max_duration=12.0)
        segments.sort(key=lambda x: float(x.get("start", 0)))

        # è¿›è¡Œè§†é¢‘åŒ¹é…ï¼ˆå¤ç”¨ build æ–¹æ³•çš„åŒ¹é…é€»è¾‘ï¼‰
        timeline = TimelineResult()
        cursor_ms = 0
        total_segments = len(segments)

        for seg_idx, seg in enumerate(segments):
            if total_segments > 0:
                match_progress = 10.0 + (seg_idx / total_segments) * 85.0
                await report_progress(match_progress)

            raw_text = str(seg.get("text", ""))
            text = raw_text.strip().strip("'\"")
            if not text:
                continue

            start_ms = int(float(seg.get("start", 0)) * 1000)
            end_ms = int(float(seg.get("end", 0)) * 1000)

            # é—´éš™å¤„ç†
            if cursor_ms > 0 and start_ms > cursor_ms:
                gap = start_ms - cursor_ms
                if gap > 2000:
                    gap_prompt = "atmospheric music video, cinematic scenes, instrumental, no lyrics"
                    gap_candidates = await self._get_candidates(gap_prompt, limit=20)
                    normalized_gap = self._normalize_candidates(gap_candidates, cursor_ms, start_ms)
                    selected_gap = self._select_diverse_candidates(normalized_gap, limit=3)
                    if not selected_gap:
                        selected_gap = [{
                            "id": str(uuid4()),
                            "source_video_id": self._settings.fallback_video_id,
                            "start_time_ms": cursor_ms,
                            "end_time_ms": start_ms,
                            "score": 0.0,
                        }]
                    for candidate in selected_gap:
                        segment_key = (
                            str(candidate.get("source_video_id")),
                            int(candidate.get("start_time_ms", 0)),
                            int(candidate.get("end_time_ms", 0)),
                        )
                        self._used_segments[segment_key] = self._used_segments.get(segment_key, 0) + 1
                    timeline.lines.append(TimelineLine(
                        text="(Instrumental)",
                        start_ms=cursor_ms,
                        end_ms=start_ms,
                        candidates=selected_gap
                    ))
                else:
                    start_ms = cursor_ms

            # å¤„ç†å½“å‰ç‰‡æ®µ
            if seg.get("is_non_lyric", False):
                candidates = []
            else:
                search_query = seg.get("search_prompt", text)
                candidates = await self._get_candidates(search_query, limit=20)

            normalized = self._normalize_candidates(candidates, start_ms, end_ms)
            selected_candidates = self._select_diverse_candidates(normalized, limit=3)

            for candidate in selected_candidates:
                segment_key = (
                    str(candidate.get("source_video_id")),
                    int(candidate.get("start_time_ms", 0)),
                    int(candidate.get("end_time_ms", 0)),
                )
                self._used_segments[segment_key] = self._used_segments.get(segment_key, 0) + 1

            timeline.lines.append(TimelineLine(
                text=text,
                start_ms=start_ms,
                end_ms=end_ms,
                candidates=selected_candidates,
            ))
            cursor_ms = max(cursor_ms, end_ms)

        # å°¾éƒ¨å¡«å……
        if audio_duration_ms > cursor_ms + 1000:
            gap_start = cursor_ms
            gap_end = audio_duration_ms
            outro_prompt = "ending music video, fade out, cinematic, atmospheric"
            outro_candidates = await self._get_candidates(outro_prompt, limit=20)
            normalized_outro = self._normalize_candidates(outro_candidates, gap_start, gap_end)
            selected_outro = self._select_diverse_candidates(normalized_outro, limit=3)
            if not selected_outro:
                selected_outro = [{
                    "id": str(uuid4()),
                    "source_video_id": self._settings.fallback_video_id,
                    "start_time_ms": gap_start,
                    "end_time_ms": gap_end,
                    "score": 0.0,
                }]
            timeline.lines.append(TimelineLine(
                text="(Outro)",
                start_ms=gap_start,
                end_ms=gap_end,
                candidates=selected_outro
            ))

        await report_progress(100.0)
        return timeline

    async def build(
        self,
        audio_path: Path | None,
        lyrics_text: Optional[str],
        language: str | None = None,
        prompt: str | None = None,
        on_progress: ProgressCallback | None = None,
    ) -> TimelineResult:
        """å®Œæ•´æ„å»ºæµç¨‹ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰ï¼šWhisper è¯†åˆ« + è§†é¢‘åŒ¹é…ã€‚"""
        self._candidate_cache.clear()
        self._used_segments.clear()  # é‡ç½®å·²ä½¿ç”¨ç‰‡æ®µè¿½è¸ª
        segments: list[dict[str, Any]] = []
        audio_duration_ms = 0

        async def report_progress(progress: float) -> None:
            if on_progress:
                await on_progress(progress)

        if audio_path:
            await report_progress(5.0)  # 5%: å¼€å§‹å¤„ç†éŸ³é¢‘
            audio_duration_ms = self._get_audio_duration(audio_path)
            self._logger.info(
                "timeline_builder.audio_info",
                path=str(audio_path),
                duration_ms=audio_duration_ms
            )
            await report_progress(10.0)  # 10%: å¼€å§‹ Whisper è¯†åˆ«
            raw_segments = await transcribe_with_timestamps(
                audio_path,
                language=language,
                prompt=prompt
            )
            segments = [dict(segment) for segment in raw_segments]
            await report_progress(30.0)  # 30%: Whisper è¯†åˆ«å®Œæˆ
        elif lyrics_text:
            for idx, line in enumerate(lyrics_text.splitlines()):
                stripped = line.strip()
                if not stripped:
                    continue
                segments.append({"text": stripped, "start": float(idx), "end": float(idx + 1)})
        else:
            raise ValueError("å¿…é¡»æä¾›éŸ³é¢‘æˆ–æ­Œè¯")

        segments = self._explode_segments(segments)
        
        # æ ‡è®°éæ­Œè¯å†…å®¹ï¼ˆä½œè¯ã€ä½œæ›²ç­‰ creditsï¼‰
        # ç­–ç•¥æ›´æ–°ï¼š
        # 1. çŸ­çš„ credits (< 10s) -> æ ‡è®°ä¸º non-lyricï¼Œä½¿ç”¨ fallback
        # 2. é•¿çš„ credits (>= 10s) -> è§†ä¸º Intro/Interludeï¼Œæ”¹å†™ text è¿›è¡Œæœç´¢
        non_lyric_count = 0
        for seg in segments:
            text = str(seg.get("text", "")).strip()
            start = float(seg.get("start", 0))
            end = float(seg.get("end", 0))
            duration_s = end - start

            if self._is_non_lyric_text(text):
                if duration_s < 10.0:
                    seg["is_non_lyric"] = True
                    non_lyric_count += 1
                    self._logger.info(
                        "timeline_builder.mark_non_lyric",
                        text=text,
                        duration_s=round(duration_s, 2),
                        message="çŸ­ Credit ä¿¡æ¯ï¼Œæ ‡è®°ä¸ºéæ­Œè¯ (Fallback)",
                    )
                else:
                    # é•¿ç‰‡æ®µï¼Œå³ä½¿åŒ…å« Credit ä¹Ÿä¸åº”è¯¥ç”¨é»‘å± Fallback
                    # æ”¹å†™ä¸ºé€šç”¨ Intro Prompt
                    seg["is_non_lyric"] = False
                    seg["search_prompt"] = "cinematic music video intro, atmospheric, slow motion"
                    self._logger.info(
                        "timeline_builder.convert_long_credit",
                        text=text,
                        duration_s=round(duration_s, 2),
                        message="é•¿ Credit ç‰‡æ®µï¼Œè½¬æ¢ä¸º Intro æœç´¢",
                    )

        if non_lyric_count > 0:
            self._logger.info(
                "timeline_builder.non_lyric_summary",
                total_count=len(segments),
                non_lyric_count=non_lyric_count,
                lyric_count=len(segments) - non_lyric_count,
                message=f"å‘ç° {non_lyric_count} ä¸ªçŸ­éæ­Œè¯ç‰‡æ®µ",
            )
            
        # åœ¨æ’åºå‰è¿›è¡Œæ—¶é•¿åˆ‡åˆ†
        # è¿™ä¼šå°† 30s çš„ Intro åˆ‡åˆ†ä¸º 3 ä¸ª 10s çš„ç‰‡æ®µï¼Œæ¯ä¸ªéƒ½ä¼šè¿›è¡Œç‹¬ç«‹çš„è§†é¢‘æœç´¢
        segments = self._split_by_duration(segments, max_duration=12.0)
        
        # æŒ‰å¼€å§‹æ—¶é—´æ’åºï¼Œç¡®ä¿æ—¶é—´çº¿è¿ç»­æ€§
        segments.sort(key=lambda x: float(x.get("start", 0)))

        timeline = TimelineResult()
        cursor_ms = 0
        total_segments = len(segments)

        for seg_idx, seg in enumerate(segments):
            # æ›´æ–°è¿›åº¦: 30% - 95% å¯¹åº”è§†é¢‘åŒ¹é…é˜¶æ®µ
            if total_segments > 0:
                match_progress = 30.0 + (seg_idx / total_segments) * 65.0
                await report_progress(match_progress)
            raw_text = str(seg.get("text", ""))
            text = raw_text.strip().strip("'\"")
            if not text:
                continue
            start_value = seg.get("start", 0)
            end_value = seg.get("end")
            start_ms = int(float(start_value) * 1000)
            if end_value is None:
                end_ms = start_ms + 1000
            else:
                end_ms = int(float(end_value) * 1000)

            # ğŸµ é—´éš™å¤„ç†ç­–ç•¥ (Gap Handling Strategy)
            # ç›®æ ‡ï¼šç¡®ä¿è§†é¢‘æ—¶é—´çº¿è¿ç»­ï¼Œæ— é»‘å±ï¼Œæ— è·³è·ƒ
            if cursor_ms > 0:  # åªæœ‰éç¬¬ä¸€å¥æ‰éœ€è¦å¤„ç†é—´éš™ï¼ˆç¬¬ä¸€å¥å‰é¢æ˜¯0ï¼‰
                if start_ms > cursor_ms:
                    gap = start_ms - cursor_ms
                    
                    # ç­–ç•¥ 1: å¤§é—´éš™ -> æ’å…¥é—´å¥ç‰‡æ®µ
                    if gap > 2000:
                        self._logger.info(
                            "timeline_builder.fill_large_gap",
                            gap_start=cursor_ms,
                            gap_end=start_ms,
                            duration=gap,
                            message="å‘ç°å¤§é—´éš™ï¼Œæ’å…¥çº¯éŸ³ä¹ç”»é¢",
                        )
                        
                        # æœç´¢çº¯éŸ³ä¹ç”»é¢
                        gap_prompt = "atmospheric music video, cinematic scenes, instrumental, no lyrics"
                        gap_candidates = await self._get_candidates(gap_prompt, limit=20)
                        normalized_gap = self._normalize_candidates(gap_candidates, cursor_ms, start_ms)
                        selected_gap = self._select_diverse_candidates(normalized_gap, limit=3)
                        
                        # å…œåº•
                        if not selected_gap:
                            selected_gap = [{
                                "id": str(uuid4()),
                                "source_video_id": self._settings.fallback_video_id,
                                "start_time_ms": cursor_ms,
                                "end_time_ms": start_ms,
                                "score": 0.0,
                            }]

                        # æ ‡è®°å·²ä½¿ç”¨
                        for candidate in selected_gap:
                            segment_key = (
                                str(candidate.get("source_video_id")),
                                int(candidate.get("start_time_ms", 0)),
                                int(candidate.get("end_time_ms", 0)),
                            )
                            self._used_segments[segment_key] = self._used_segments.get(segment_key, 0) + 1

                        timeline.lines.append(
                            TimelineLine(
                                text="(Instrumental)",
                                start_ms=cursor_ms,
                                end_ms=start_ms,
                                candidates=selected_gap
                            )
                        )
                    
                    # ç­–ç•¥ 2: å°é—´éš™ -> å¸æ”¶ï¼ˆå‘å‰å»¶ä¼¸å½“å‰ç‰‡æ®µï¼‰
                    else:
                        self._logger.info(
                            "timeline_builder.absorb_small_gap",
                            original_start=start_ms,
                            new_start=cursor_ms,
                            gap_absorbed=gap,
                            message="å¸æ”¶å¾®å°é—´éš™ï¼Œå‘å‰å»¶ä¼¸å½“å‰ç‰‡æ®µ",
                        )
                        start_ms = cursor_ms  # ä¿®æ”¹å½“å‰ç‰‡æ®µçš„å¼€å§‹æ—¶é—´

            # å¤„ç†å½“å‰ç‰‡æ®µ
            if seg.get("is_non_lyric", False):
                # çŸ­ Credit -> Fallback
                candidates = []
            else:
                # ä¼˜å…ˆä½¿ç”¨ search_prompt (é’ˆå¯¹ Long Credit/Intro)
                search_query = seg.get("search_prompt", text)
                candidates = await self._get_candidates(search_query, limit=20)

            normalized = self._normalize_candidates(candidates, start_ms, end_ms)

            # é€‰æ‹©æœªä½¿ç”¨æˆ–ä½¿ç”¨æ¬¡æ•°æœ€å°‘çš„ç‰‡æ®µ
            selected_candidates = self._select_diverse_candidates(normalized, limit=3)

            # æ ‡è®°æ‰€æœ‰å€™é€‰ç‰‡æ®µä¸ºå·²ä½¿ç”¨ï¼ˆé˜²æ­¢åç»­å¥å­é‡å¤ä½¿ç”¨ï¼‰
            for candidate in selected_candidates:
                segment_key = (
                    str(candidate.get("source_video_id")),
                    int(candidate.get("start_time_ms", 0)),
                    int(candidate.get("end_time_ms", 0)),
                )
                self._used_segments[segment_key] = self._used_segments.get(segment_key, 0) + 1

            timeline.lines.append(
                TimelineLine(
                    text=text,
                    start_ms=start_ms,
                    end_ms=end_ms,
                    candidates=selected_candidates,
                )
            )
            cursor_ms = max(cursor_ms, end_ms)
            
        # ğŸµ å°¾éƒ¨å¡«å……é€»è¾‘ (Tail Gap Filling)
        self._logger.info(
            "timeline_builder.check_tail_gap",
            audio_duration_ms=audio_duration_ms,
            cursor_ms=cursor_ms,
            gap=audio_duration_ms - cursor_ms,
            threshold=1000,
            should_fill=audio_duration_ms > cursor_ms + 1000
        )
        
        if audio_duration_ms > cursor_ms + 1000:
            gap_start = cursor_ms
            gap_end = audio_duration_ms
            self._logger.info(
                "timeline_builder.fill_tail_gap",
                gap_start=gap_start,
                gap_end=gap_end,
                duration=gap_end - gap_start,
                message="å¡«å……å°¾éƒ¨ç©ºéš™",
            )
            
            outro_prompt = "ending music video, fade out, cinematic, atmospheric"
            outro_candidates = await self._get_candidates(outro_prompt, limit=20)
            normalized_outro = self._normalize_candidates(outro_candidates, gap_start, gap_end)
            selected_outro = self._select_diverse_candidates(normalized_outro, limit=3)
            
            # å¦‚æœå› ä¸ºé‡å ç­‰åŸå› æ²¡æœ‰é€‰åˆ°å€™é€‰ï¼Œå¼ºåˆ¶ä½¿ç”¨ fallback
            if not selected_outro:
                self._logger.warning(
                    "timeline_builder.outro_fallback",
                    gap_start=gap_start,
                    gap_end=gap_end,
                    message="Outro æœç´¢æ— å¯ç”¨å€™é€‰ï¼Œä½¿ç”¨ Fallback",
                )
                selected_outro = [{
                    "id": str(uuid4()),
                    "source_video_id": self._settings.fallback_video_id,
                    "start_time_ms": gap_start,
                    "end_time_ms": gap_end,
                    "score": 0.0,
                }]

            timeline.lines.append(
                TimelineLine(
                    text="(Outro)",
                    start_ms=gap_start,
                    end_ms=gap_end,
                    candidates=selected_outro
                )
            )

        await report_progress(100.0)  # 100%: æ—¶é—´çº¿ç”Ÿæˆå®Œæˆ
        return timeline

    def _normalize_candidates(
        self, raw_candidates: list[dict[str, int | float | str]], start_ms: int, end_ms: int
    ) -> list[dict[str, int | float | str]]:
        """
        è§„èŒƒåŒ–å€™é€‰è§†é¢‘ç‰‡æ®µï¼Œè¿‡æ»¤æ‰æ—¶é•¿ä¸¥é‡ä¸åŒ¹é…çš„å€™é€‰ã€‚

        è¿‡æ»¤ç­–ç•¥ï¼š
        - å¦‚æœ API è¿”å›çš„è§†é¢‘ç‰‡æ®µæ—¶é•¿ä¸æ­Œè¯æ—¶é•¿ç›¸å·®è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™è·³è¿‡è¯¥å€™é€‰
        - é˜ˆå€¼ï¼šæ­Œè¯æ—¶é•¿ â‰¥ 5ç§’ ä¸” è§†é¢‘æ—¶é•¿ < æ­Œè¯æ—¶é•¿ 50% æ—¶è¿‡æ»¤
        - ä¾‹å¦‚ï¼šæ­Œè¯ 30 ç§’ï¼Œä½†è§†é¢‘åªæœ‰ 5 ç§’ â†’ è¿‡æ»¤æ‰
        """
        lyric_duration_ms = end_ms - start_ms
        lyric_duration_s = lyric_duration_ms / 1000.0

        def _candidate_defaults(candidate: dict[str, int | float | str]) -> dict[str, int | float | str] | None:
            # ğŸ”§ ä¿®å¤: ä» API è¿”å›ç‰‡æ®µçš„ä¸­é—´ä½ç½®æˆªå–ï¼Œä»¥è·å¾—æœ€åŒ¹é…çš„ç”»é¢
            # åŸå› ï¼šAI åŒ¹é…çš„ç²¾å½©ç”»é¢å¾€å¾€åœ¨ç‰‡æ®µä¸­é—´ï¼Œè€Œä¸æ˜¯å¼€å¤´
            api_start = int(candidate.get("start", start_ms))
            api_end = int(candidate.get("end", end_ms))
            lyric_duration = end_ms - start_ms

            # æ£€æŸ¥è§†é¢‘ç‰‡æ®µæ—¶é•¿æ˜¯å¦è¶³å¤Ÿ
            api_duration_ms = api_end - api_start
            api_duration_s = api_duration_ms / 1000.0

            # è¿‡æ»¤ç­–ç•¥ï¼šå¦‚æœæ­Œè¯æ—¶é•¿ â‰¥ 5ç§’ ä¸” è§†é¢‘æ—¶é•¿ < æ­Œè¯æ—¶é•¿çš„ 50%ï¼Œåˆ™è¿‡æ»¤æ‰
            if lyric_duration_s >= 5.0 and api_duration_ms < lyric_duration_ms * 0.5:
                self._logger.warning(
                    "timeline_builder.duration_mismatch",
                    video_id=candidate.get("video_id"),
                    lyric_duration_s=round(lyric_duration_s, 2),
                    api_duration_s=round(api_duration_s, 2),
                    shortage_s=round(lyric_duration_s - api_duration_s, 2),
                    shortage_pct=round((1 - api_duration_s / lyric_duration_s) * 100, 1),
                    message="è§†é¢‘ç‰‡æ®µæ—¶é•¿ä¸¥é‡ä¸è¶³ï¼Œè·³è¿‡è¯¥å€™é€‰",
                )
                return None

            # è®¡ç®—APIç‰‡æ®µçš„ä¸­é—´ä½ç½®
            api_duration = api_end - api_start
            api_middle = api_start + (api_duration // 2)

            # ä»ä¸­é—´ä½ç½®å‘å‰åç§»ä¸€åŠæ­Œè¯æ—¶é•¿ï¼Œä½¿æ­Œè¯æ—¶é•¿å±…ä¸­
            clip_start = api_middle - (lyric_duration // 2)
            clip_end = clip_start + lyric_duration

            # ğŸ”§ ä¿®å¤ï¼šå…è®¸è¶…å‡ºAPIç‰‡æ®µè¾¹ç•Œï¼Œç”± video_fetcher è‡ªåŠ¨å¤„ç†å¾ªç¯/è£å‰ª
            #
            # åŸé—®é¢˜ï¼šå½“APIè¿”å›çš„ç‰‡æ®µçŸ­äºæ­Œè¯æ—¶é•¿æ—¶ï¼Œè¾¹ç•Œæ£€æŸ¥ä¼šå°†é€‰æ‹©æˆªæ–­åˆ°APIé•¿åº¦
            # ä¾‹å¦‚ï¼šæ­Œè¯éœ€è¦8sï¼ŒAPIåªæœ‰5sï¼ŒåŸé€»è¾‘ä¼šå°†é€‰æ‹©æˆªæ–­ä¸º5sï¼Œå¯¼è‡´æ—¶é•¿ä¸è¶³
            #
            # æ–°é€»è¾‘ï¼šä¿æŒå®Œæ•´çš„æ­Œè¯æ—¶é•¿éœ€æ±‚ï¼Œè®© video_fetcher å¤„ç†è¾¹ç•Œæƒ…å†µ
            # - å¦‚æœè¶…å‡ºè§†é¢‘æœ«å°¾ï¼Œvideo_fetcher ä¼šè‡ªåŠ¨ä½¿ç”¨å¾ªç¯æ¨¡å¼ (_cut_clip_with_loop)
            # - å¦‚æœèµ·å§‹ä½ç½®ä¸ºè´Ÿï¼Œè°ƒæ•´åˆ°ä»è§†é¢‘å¼€å¤´å¼€å§‹
            if clip_start < api_start:
                # èµ·å§‹ä½ç½®æå‰ï¼šä»APIå¼€å¤´å¼€å§‹ï¼Œä¿æŒæ­Œè¯æ—¶é•¿
                clip_start = api_start
                clip_end = clip_start + lyric_duration
                # ä¸å†é™åˆ¶ clip_endï¼Œå…è®¸è¶…å‡º api_end
            # ä¸å¤„ç† clip_end > api_end çš„æƒ…å†µï¼Œè®©å®ƒè‡ªç„¶è¶…å‡º
            # video_fetcher ä¼šæ£€æµ‹åˆ°å¹¶ä½¿ç”¨å¾ªç¯æ¨¡å¼

            return {
                "id": str(uuid4()),
                "source_video_id": candidate.get("video_id", self._settings.fallback_video_id),
                "start_time_ms": clip_start,              # ä»ä¸­é—´ä½ç½®å¼€å§‹æˆªå–
                "end_time_ms": clip_end,                  # ä¿æŒæ­Œè¯æ—¶é•¿
                "score": candidate.get("score", 0.0),
                # ä¿ç•™åŸå§‹æ•°æ®ä¾›å‚è€ƒ
                "api_start_ms": api_start,
                "api_end_ms": api_end,
                "api_middle_ms": api_middle,
                "api_duration_ms": api_duration_ms,
                "lyric_start_ms": start_ms,
                "lyric_end_ms": end_ms,
                "lyric_duration_ms": lyric_duration_ms,
            }

        if raw_candidates:
            # å¤„ç†æ‰€æœ‰å€™é€‰ï¼Œè¿‡æ»¤æ‰ Noneï¼ˆæ—¶é•¿ä¸åŒ¹é…çš„ï¼‰
            normalized = []
            for c in raw_candidates:
                result = _candidate_defaults(c)
                if result is not None:
                    normalized.append(result)

            # å¦‚æœæ‰€æœ‰å€™é€‰éƒ½è¢«è¿‡æ»¤æ‰äº†ï¼Œè¿”å› fallback
            if not normalized:
                self._logger.warning(
                    "timeline_builder.all_candidates_filtered",
                    lyric_duration_s=round(lyric_duration_s, 2),
                    original_count=len(raw_candidates),
                    message="æ‰€æœ‰å€™é€‰è§†é¢‘æ—¶é•¿éƒ½ä¸åŒ¹é…ï¼Œä½¿ç”¨ fallback è§†é¢‘",
                )
                return [
                    {
                        "id": str(uuid4()),
                        "source_video_id": self._settings.fallback_video_id,
                        "start_time_ms": start_ms,
                        "end_time_ms": end_ms,
                        "score": 0.0,
                    }
                ]

            return normalized

        return [
            {
                "id": str(uuid4()),
                "source_video_id": self._settings.fallback_video_id,
                "start_time_ms": start_ms,
                "end_time_ms": end_ms,
                "score": 0.0,
            }
        ]

    async def _get_candidates(self, text: str, limit: int) -> list[dict[str, Any]]:
        """
        è·å–å€™é€‰ç‰‡æ®µï¼Œæ”¯æŒä¸¤ç§ç­–ç•¥ï¼š

        ç­–ç•¥1: å¼ºåˆ¶æ”¹å†™æ¨¡å¼ (QUERY_REWRITE_MANDATORY=true)
        1. AIæ”¹å†™ï¼ˆç¬¬1æ¬¡ï¼‰ â†’ æŸ¥è¯¢
        2. æ— å€™é€‰ â†’ AIæ”¹å†™ï¼ˆç¬¬2æ¬¡ï¼Œé€šç”¨åŒ–ï¼‰ â†’ é‡è¯•
        3. ä»æ— å€™é€‰ â†’ AIæ”¹å†™ï¼ˆç¬¬3æ¬¡ï¼Œæç®€åŒ–ï¼‰ â†’ é‡è¯•
        4. ä»æ— å€™é€‰ â†’ è¿”å›ç©ºï¼ˆä½¿ç”¨fallbackï¼‰

        ç­–ç•¥2: æŒ‰éœ€æ”¹å†™æ¨¡å¼ (QUERY_REWRITE_MANDATORY=falseï¼Œé»˜è®¤)
        1. åŸå§‹æŸ¥è¯¢ â†’ æœ‰å€™é€‰ â†’ ä½¿ç”¨
        2. åŸå§‹æŸ¥è¯¢ â†’ æ— å€™é€‰ â†’ AIæ”¹å†™ï¼ˆç¬¬1æ¬¡ï¼‰ â†’ é‡è¯•
        3. ä»æ— å€™é€‰ â†’ AIæ”¹å†™ï¼ˆç¬¬2æ¬¡ï¼Œé€šç”¨åŒ–ï¼‰ â†’ é‡è¯•
        4. ä»æ— å€™é€‰ â†’ AIæ”¹å†™ï¼ˆç¬¬3æ¬¡ï¼Œæç®€åŒ–ï¼‰ â†’ é‡è¯•
        5. ä»æ— å€™é€‰ â†’ è¿”å›ç©ºï¼ˆä½¿ç”¨fallbackï¼‰
        """
        key = (text, limit)
        if key not in self._candidate_cache:
            candidates: list[dict[str, Any]] = []
            query_text = text

            # å¦‚æœå¯ç”¨äº†æ”¹å†™ä¸”é…ç½®ä¸ºå¼ºåˆ¶æ”¹å†™ï¼Œç¬¬ä¸€æ¬¡æŸ¥è¯¢å°±æ”¹å†™
            if self._rewriter._enabled and self._settings.query_rewrite_mandatory:
                self._logger.info(
                    "timeline_builder.mandatory_rewrite",
                    original=text[:30],
                    message="å¼ºåˆ¶æ”¹å†™æ¨¡å¼ï¼Œè·³è¿‡åŸå§‹æŸ¥è¯¢",
                )
                # ç›´æ¥è¿›å…¥æ”¹å†™æµç¨‹ï¼Œä» attempt=0 å¼€å§‹
                query_text = await self._rewriter.rewrite(text, attempt=0)
                self._logger.info(
                    "timeline_builder.mandatory_rewrite_query",
                    original=text[:30],
                    rewritten=query_text[:30],
                )
                candidates = await client.search_segments(query_text, limit=limit)

                # å¦‚æœç¬¬ä¸€æ¬¡æ”¹å†™å°±æˆåŠŸï¼Œè®°å½•æ—¥å¿—
                if candidates:
                    self._logger.info(
                        "timeline_builder.mandatory_rewrite_success",
                        original=text[:30],
                        rewritten=query_text[:50],
                        count=len(candidates),
                    )
            else:
                # ç¬¬ä¸€æ­¥ï¼šå°è¯•åŸå§‹æŸ¥è¯¢
                candidates = await client.search_segments(text, limit=limit)

            # ç¬¬äºŒæ­¥ï¼šå¦‚æœæ— å€™é€‰ä¸”å¯ç”¨äº†æ”¹å†™ï¼Œæ™ºèƒ½é‡è¯•æ”¹å†™
            if not candidates and self._rewriter._enabled:
                max_attempts = self._settings.query_rewrite_max_attempts
                # å¦‚æœå·²ç»æ‰§è¡Œè¿‡å¼ºåˆ¶æ”¹å†™ï¼Œä» attempt=1 å¼€å§‹ï¼ˆè·³è¿‡ç¬¬ä¸€æ¬¡ï¼‰
                start_attempt = 1 if self._settings.query_rewrite_mandatory else 0

                for attempt in range(start_attempt, max_attempts):
                    self._logger.info(
                        "timeline_builder.fallback_to_rewrite",
                        original=text[:30],
                        attempt=attempt + 1,
                        max_attempts=max_attempts,
                    )

                    rewritten_query = await self._rewriter.rewrite(text, attempt=attempt)

                    # å¦‚æœæ”¹å†™åçš„æŸ¥è¯¢ä¸åŒï¼Œåˆ™é‡è¯•
                    if rewritten_query != text and rewritten_query != query_text:
                        candidates = await client.search_segments(rewritten_query, limit=limit)
                        self._logger.info(
                            "timeline_builder.rewrite_result",
                            original=text[:30],
                            rewritten=rewritten_query[:30],
                            attempt=attempt + 1,
                            count=len(candidates),
                        )

                        # å¦‚æœæ‰¾åˆ°å€™é€‰ï¼Œç«‹å³é€€å‡ºå¾ªç¯
                        if candidates:
                            self._logger.info(
                                "timeline_builder.rewrite_success",
                                original=text[:30],
                                attempt=attempt + 1,
                                final_query=rewritten_query[:50],
                                count=len(candidates),
                            )
                            break
                    else:
                        self._logger.warning(
                            "timeline_builder.rewrite_identical",
                            original=text[:30],
                            attempt=attempt + 1,
                        )

            self._candidate_cache[key] = candidates

        candidates = [candidate.copy() for candidate in self._candidate_cache[key]]
        count = len(candidates)
        log_method = self._logger.warning if count == 0 else self._logger.info
        log_method(
            "timeline_builder.candidates",
            text_preview=text[:30],
            count=count,
            use_mock=self._use_mock_segments,
        )
        return candidates

    def _select_diverse_candidates(
        self, candidates: list[dict[str, int | float | str]], limit: int
    ) -> list[dict[str, int | float | str]]:
        """
        ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©å¤šæ ·åŒ–çš„ç‰‡æ®µï¼Œä¸¥æ ¼ç¡®ä¿æ¯ä¸ªç‰‡æ®µåªä½¿ç”¨ä¸€æ¬¡ã€‚

        **ä¸¥æ ¼ç­–ç•¥**ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚ï¼‰ï¼š
        1. å®Œå…¨ç¦æ­¢é‡å¤ä½¿ç”¨ï¼šusage_count > 0 çš„ç‰‡æ®µç›´æ¥å‰”é™¤
        2. å®Œå…¨ç¦æ­¢é‡å ï¼šä»»ä½•é‡å  > 0 çš„ç‰‡æ®µç›´æ¥å‰”é™¤
        3. å¦‚æœæ²¡æœ‰å¯ç”¨ç‰‡æ®µï¼Œè¿”å›ç©ºï¼ˆä½¿ç”¨ fallback è§†é¢‘ï¼‰
        4. æŒ‰è¯„åˆ†é™åºæ’åºé€‰æ‹©æœ€ä½³çš„æœªä½¿ç”¨ç‰‡æ®µ
        """
        if not candidates:
            return []

        # ä¸ºæ¯ä¸ªå€™é€‰ç‰‡æ®µæ£€æµ‹ä½¿ç”¨æ¬¡æ•°å’Œæ—¶é—´é‡å 
        valid_candidates: list[CandidateWithUsage] = []
        rejected_count = 0

        for candidate in candidates:
            video_id = str(candidate.get("source_video_id", ""))
            start_ms = int(candidate.get("start_time_ms", 0))
            end_ms = int(candidate.get("end_time_ms", 0))
            segment_key = (video_id, start_ms, end_ms)

            # ç­–ç•¥1ï¼šå®Œå…¨ç¦æ­¢é‡å¤ä½¿ç”¨ - æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            usage_count = self._used_segments.get(segment_key, 0)
            if usage_count > 0:
                self._logger.info(
                    "timeline_builder.reject_reused",
                    video_id=video_id,
                    start_ms=start_ms,
                    end_ms=end_ms,
                    usage_count=usage_count,
                    message="ä¸¥æ ¼å»é‡ï¼šç‰‡æ®µå·²ä½¿ç”¨è¿‡ï¼Œç›´æ¥å‰”é™¤",
                )
                rejected_count += 1
                continue

            # ç­–ç•¥2ï¼šå®Œå…¨ç¦æ­¢é‡å  - æ£€æŸ¥ä¸æ‰€æœ‰å·²ä½¿ç”¨ç‰‡æ®µçš„é‡å 
            has_overlap = False
            for used_key in self._used_segments.keys():
                used_video_id, used_start, used_end = used_key
                if used_video_id == video_id:
                    overlap_ratio = calculate_overlap_ratio(start_ms, end_ms, used_start, used_end)
                    if overlap_ratio > 0:
                        has_overlap = True
                        self._logger.info(
                            "timeline_builder.reject_overlap",
                            video_id=video_id,
                            start_ms=start_ms,
                            end_ms=end_ms,
                            overlapping_with=used_key,
                            overlap_ratio=round(overlap_ratio, 3),
                            message="ä¸¥æ ¼å»é‡ï¼šç‰‡æ®µä¸å·²ä½¿ç”¨ç‰‡æ®µé‡å ï¼Œç›´æ¥å‰”é™¤",
                        )
                        rejected_count += 1
                        break

            if has_overlap:
                continue

            # é€šè¿‡æ‰€æœ‰æ£€æŸ¥ï¼ŒåŠ å…¥æœ‰æ•ˆå€™é€‰åˆ—è¡¨
            valid_candidates.append({
                "candidate": candidate,
                "usage_count": 0,  # è‚¯å®šæ˜¯ 0ï¼Œå› ä¸ºå·²ç»è¿‡æ»¤æ‰äº† > 0 çš„
                "score": float(candidate.get("score", 0.0)),
            })

        # ç­–ç•¥4ï¼šæŒ‰è¯„åˆ†é™åºæ’åºé€‰æ‹©æœ€ä½³çš„
        valid_candidates.sort(key=lambda x: -x["score"])

        # æå–å€™é€‰ç‰‡æ®µå¹¶é™åˆ¶æ•°é‡
        selected: list[dict[str, int | float | str]] = [
            item["candidate"] for item in valid_candidates[:limit]
        ]

        # ç­–ç•¥3ï¼šå¦‚æœæ²¡æœ‰å¯ç”¨ç‰‡æ®µï¼Œè¿”å›ç©ºï¼ˆè§¦å‘ fallbackï¼‰
        if not selected:
            self._logger.warning(
                "timeline_builder.no_valid_candidates",
                total_candidates=len(candidates),
                rejected_count=rejected_count,
                message="ä¸¥æ ¼å»é‡ï¼šæ‰€æœ‰å€™é€‰éƒ½å·²ä½¿ç”¨æˆ–é‡å ï¼Œå°†ä½¿ç”¨ fallback è§†é¢‘",
            )
            return []

        # è®°å½•é€‰ä¸­çš„ç‰‡æ®µè¯¦ç»†ä¿¡æ¯
        for idx, item in enumerate(valid_candidates[:limit]):
            candidate = item["candidate"]
            self._logger.info(
                "timeline_builder.selected_clip",
                index=idx + 1,
                video_id=candidate.get("source_video_id"),
                start_ms=candidate.get("start_time_ms"),
                end_ms=candidate.get("end_time_ms"),
                duration_ms=candidate.get("end_time_ms", 0) - candidate.get("start_time_ms", 0),
                score=candidate.get("score"),
                message="ä¸¥æ ¼å»é‡é€šè¿‡ï¼šæœªä½¿ç”¨ä¸”æ— é‡å ",
            )

        self._logger.info(
            "timeline_builder.strict_deduplication_summary",
            total_candidates=len(candidates),
            valid_count=len(valid_candidates),
            rejected_count=rejected_count,
            selected_count=len(selected),
            message=f"ä¸¥æ ¼å»é‡ï¼šä»{len(candidates)}ä¸ªå€™é€‰ä¸­ç­›é€‰å‡º{len(valid_candidates)}ä¸ªæœ‰æ•ˆï¼Œé€‰æ‹©äº†{len(selected)}ä¸ª",
        )

        return selected

    def _explode_segments(self, segments: list[dict[str, Any]]) -> list[dict[str, Any]]:
        exploded: list[dict[str, Any]] = []
        for seg in segments:
            text = str(seg.get("text", "")).strip()
            if not text:
                continue
            pieces = [piece.strip() for piece in self._split_pattern.split(text) if piece and piece.strip()]
            if len(pieces) <= 1:
                exploded.append(seg)
                continue
            start = float(seg.get("start", 0.0))
            end = float(seg.get("end", start + 1.0))
            if end <= start:
                end = start + 1.0
            duration = end - start
            total_chars = sum(len(piece) for piece in pieces) or len(pieces)
            cursor = start
            for idx, piece in enumerate(pieces):
                ratio = len(piece) / total_chars if total_chars else 1.0 / len(pieces)
                chunk_duration = duration * ratio
                chunk_end = end if idx == len(pieces) - 1 else cursor + chunk_duration
                exploded.append(
                    {
                        **seg,
                        "text": piece,
                        "start": cursor,
                        "end": chunk_end,
                    }
                )
                cursor = chunk_end
        return exploded
