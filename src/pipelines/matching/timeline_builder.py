"""æ„å»ºæ­Œè¯ä¸è§†é¢‘ç‰‡æ®µçš„æ—¶é—´çº¿ã€‚"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Callable, Coroutine, Optional, TypedDict
from uuid import uuid4

import structlog

from src.infra.config.settings import get_settings
from src.pipelines.lyrics_ingest.transcriber import transcribe_with_timestamps
from src.services.matching.query_rewriter import QueryRewriter
from src.services.matching.twelvelabs_client import client
from src.audio.beat_detector import BeatAnalysisResult, find_nearest_beat
from src.audio.onset_detector import OnsetResult
from src.services.matching.action_detector import action_detector
from src.services.matching.beat_aligner import beat_aligner
from src.services.matching.twelvelabs_video_fetcher import video_fetcher

# è¿›åº¦å›è°ƒç±»å‹: async def callback(progress: float) -> None
ProgressCallback = Callable[[float], Coroutine[Any, Any, None]]


def calculate_overlap_ratio(start1: int, end1: int, start2: int, end2: int) -> float:
    """è®¡ç®—ä¸¤ä¸ªæ—¶é—´æ®µçš„é‡å æ¯”ä¾‹ã€‚

    è¿”å›: é‡å éƒ¨åˆ†å è¾ƒçŸ­ç‰‡æ®µçš„æ¯”ä¾‹ (0.0 åˆ° 1.0)
    """
    overlap_start = max(start1, start2)
    overlap_end = min(end1, end2)
    overlap = max(0, overlap_end - overlap_start)

    if overlap == 0:
        return 0.0

    duration1 = end1 - start1
    duration2 = end2 - start2
    shorter_duration = min(duration1, duration2)

    if shorter_duration == 0:
        return 0.0

    return overlap / shorter_duration


@dataclass
class TimelineLine:
    text: str
    start_ms: int
    end_ms: int
    candidates: list[dict]


@dataclass
class TimelineResult:
    lines: list[TimelineLine] = field(default_factory=list)


class CandidateWithUsage(TypedDict):
    candidate: dict[str, int | float | str]
    usage_count: int
    score: float


class TimelineBuilder:
    def __init__(self) -> None:
        self._settings = get_settings()
        self._use_mock_segments = not self._settings.tl_live_enabled
        self._candidate_cache: dict[tuple[str, int], list[dict[str, Any]]] = {}
        self._logger = structlog.get_logger(__name__)
        self._split_pattern = re.compile(r"(?:\r?\n)+|[ï¼Œ,ã€‚ï¼ï¼Ÿ!?ï¼›;â€¦]")
        self._rewriter = QueryRewriter()
        # è¿½è¸ªå·²ä½¿ç”¨çš„è§†é¢‘ç‰‡æ®µï¼Œé¿å…é‡å¤
        # key = (video_id, start_ms, end_ms), value = ä½¿ç”¨æ¬¡æ•°
        self._used_segments: dict[tuple[str, int, int], int] = {}
        # é‡å é˜ˆå€¼ï¼šé›¶å®¹å¿ï¼ä»»ä½•é‡å éƒ½ä¸å…è®¸
        self._overlap_threshold = 0.0  # ä»»ä½•é‡å  > 0 å°±è·³è¿‡
        # ç¼“å­˜æ‰€æœ‰æ›¾ç»è§è¿‡çš„å€™é€‰ç‰‡æ®µï¼Œç”¨äºéšæœºé€‰æ‹©
        self._all_seen_candidates: list[dict[str, Any]] = []
        # å¡ç‚¹ç›¸å…³é…ç½®
        self._beat_align_max_offset_ms = 200  # ç”»é¢åˆ‡æ¢æœ€å¤šæå‰/å»¶å 200ms å¯¹é½èŠ‚æ‹

        # ç”»é¢è¿è´¯æ€§ï¼šè¿½è¸ªä¸Šä¸€ä¸ªä½¿ç”¨çš„è§†é¢‘ï¼Œä¼˜å…ˆé€‰æ‹©åŒæºç‰‡æ®µ
        self._last_used_video_id: str | None = None
        self._continuity_bonus = 0.15  # åŒæºè§†é¢‘çš„è¯„åˆ†åŠ æˆ

        # é€šç”¨æœç´¢æŸ¥è¯¢è¯åˆ—è¡¨ï¼Œç”¨äºè·å–å¤šæ ·åŒ–çš„ç´ æ
        self._generic_queries = [
            "action scene",
            "character running",
            "chase scene",
            "funny moment",
            "cartoon animation",
            "character interaction",
            "dramatic scene",
            "comedy scene",
        ]
        self._generic_query_index = 0

    def _is_non_lyric_text(self, text: str) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºéæ­Œè¯å†…å®¹ï¼ˆå¦‚ä½œè¯ã€ä½œæ›²ã€ç¼–æ›²ç­‰æ ‡æ³¨ï¼‰ã€‚

        è¯†åˆ«æ¨¡å¼ï¼š
        - "ä½œè¯ XX" / "è¯ XX"
        - "ä½œæ›² XX" / "æ›² XX"
        - "ç¼–æ›² XX" / "ç¼– XX"
        - "æ¼”å”± XX" / "å”± XX"
        - "åˆ¶ä½œ XX"
        - çº¯è‹±æ–‡çš„ creditsï¼ˆå¦‚ "Lyrics by", "Music by"ï¼‰
        """
        text = text.strip()

        # ä¸­æ–‡ credits æ¨¡å¼
        non_lyric_patterns = [
            r"^ä½œè¯[\s:ï¼š]",
            r"^è¯[\s:ï¼š]",
            r"^ä½œæ›²[\s:ï¼š]",
            r"^æ›²[\s:ï¼š]",
            r"^ç¼–æ›²[\s:ï¼š]",
            r"^ç¼–[\s:ï¼š]",
            r"^æ¼”å”±[\s:ï¼š]",
            r"^å”±[\s:ï¼š]",
            r"^åˆ¶ä½œ[\s:ï¼š]",
            r"^ç›‘åˆ¶[\s:ï¼š]",
            r"^æ··éŸ³[\s:ï¼š]",
            r"^æ¯å¸¦[\s:ï¼š]",
        ]

        # è‹±æ–‡ credits æ¨¡å¼
        english_patterns = [
            r"(?i)^lyrics\s+by",
            r"(?i)^music\s+by",
            r"(?i)^composed\s+by",
            r"(?i)^arranged\s+by",
            r"(?i)^performed\s+by",
            r"(?i)^produced\s+by",
        ]

        all_patterns = non_lyric_patterns + english_patterns

        for pattern in all_patterns:
            if re.search(pattern, text):
                return True

        return False

    def _align_start_to_beat(
        self,
        start_ms: int,
        end_ms: int,
        beats: BeatAnalysisResult | None,
        prev_end_ms: int = 0,
    ) -> tuple[int, int]:
        """å°†ç”»é¢åˆ‡æ¢ç‚¹ï¼ˆstart_msï¼‰å¯¹é½åˆ°æœ€è¿‘çš„èŠ‚æ‹ã€‚

        ç®€åŒ–ç‰ˆå¡ç‚¹ï¼šè®©æ¯æ¬¡ç”»é¢åˆ‡æ¢éƒ½è½åœ¨éŸ³ä¹èŠ‚æ‹ä¸Šï¼Œ
        è§†è§‰æ•ˆæœä¼šæ›´æœ‰èŠ‚å¥æ„Ÿã€‚

        Args:
            start_ms: åŸå§‹å¼€å§‹æ—¶é—´
            end_ms: åŸå§‹ç»“æŸæ—¶é—´
            beats: èŠ‚æ‹åˆ†æç»“æœ
            prev_end_ms: ä¸Šä¸€ä¸ªç‰‡æ®µçš„ç»“æŸæ—¶é—´ï¼ˆé˜²æ­¢é‡å ï¼‰

        Returns:
            (aligned_start_ms, aligned_end_ms) å¯¹é½åçš„æ—¶é—´
        """
        if not beats or not self._settings.beat_sync_enabled:
            return start_ms, end_ms

        # æ‰¾æœ€è¿‘çš„èŠ‚æ‹
        result = find_nearest_beat(
            beats, start_ms, max_offset_ms=self._beat_align_max_offset_ms
        )

        if result is None:
            return start_ms, end_ms

        nearest_beat_ms, offset_ms = result

        # ç¡®ä¿ä¸ä¸ä¸Šä¸€ä¸ªç‰‡æ®µé‡å 
        if nearest_beat_ms < prev_end_ms:
            return start_ms, end_ms

        # ä¿æŒæ—¶é•¿ä¸å˜ï¼Œåªè°ƒæ•´èµ·æ­¢æ—¶é—´
        duration = end_ms - start_ms
        aligned_start = nearest_beat_ms
        aligned_end = aligned_start + duration

        if offset_ms != 0:
            self._logger.debug(
                "timeline_builder.beat_aligned",
                original_start=start_ms,
                aligned_start=aligned_start,
                offset_ms=offset_ms,
                nearest_beat=nearest_beat_ms,
            )

        return aligned_start, aligned_end

    def _get_audio_duration(self, audio_path: Path) -> int:
        """ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ã€‚"""
        import subprocess

        cmd = [
            "ffprobe",
            "-v",
            "error",
            "-show_entries",
            "format=duration",
            "-of",
            "default=noprint_wrappers=1:nokey=1",
            audio_path.as_posix(),
        ]
        try:
            result = subprocess.run(
                cmd,
                check=False,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                timeout=10,
            )
            if result.returncode == 0 and result.stdout.strip():
                return int(float(result.stdout.strip()) * 1000)
        except Exception as exc:
            self._logger.warning("ffprobe.audio_duration_failed", path=audio_path, error=str(exc))
        return 0

    def _split_by_duration(
        self, segments: list[dict[str, Any]], max_duration: float = 12.0
    ) -> list[dict[str, Any]]:
        """å°†è¿‡é•¿çš„ç‰‡æ®µæŒ‰æ—¶é•¿åˆ‡åˆ†ä¸ºæ›´å°çš„ç‰‡æ®µï¼Œä»¥å¢åŠ ç”»é¢ä¸°å¯Œåº¦ã€‚"""
        split_segments: list[dict[str, Any]] = []
        for seg in segments:
            start = float(seg.get("start", 0))
            end = float(seg.get("end", 0))
            duration = end - start

            if duration <= max_duration:
                split_segments.append(seg)
                continue

            # è®¡ç®—éœ€è¦åˆ‡åˆ†çš„å—æ•°
            num_chunks = int(duration // max_duration) + 1
            chunk_duration = duration / num_chunks

            text = seg.get("text", "")
            base_prompt = seg.get("search_prompt", "")

            for i in range(num_chunks):
                chunk_start = start + (i * chunk_duration)
                chunk_end = chunk_start + chunk_duration

                # åˆ›å»ºæ–°ç‰‡æ®µï¼Œå¤åˆ¶å…ƒæ•°æ®
                new_seg = seg.copy()
                new_seg["start"] = chunk_start
                new_seg["end"] = chunk_end

                # å¦‚æœæœ‰æœç´¢æç¤ºè¯ï¼Œæ·»åŠ å˜åŒ–ä»¥å¢åŠ å¤šæ ·æ€§
                if base_prompt:
                    new_seg["search_prompt"] = f"{base_prompt}, scene {i + 1}"

                # å¯¹äºé•¿æ–‡æœ¬ï¼ˆå¦‚ Creditsï¼‰ï¼Œåç»­ç‰‡æ®µå¯ä»¥ä¸å†æ˜¾ç¤ºæ–‡æœ¬ï¼Œæˆ–è€…ä¿ç•™
                # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œä¿ç•™æ–‡æœ¬ï¼Œä½†ç”»é¢ä¼šå˜

                split_segments.append(new_seg)

            self._logger.info(
                "timeline_builder.split_long_segment",
                original_text=text[:20],
                original_duration=round(duration, 2),
                chunks=num_chunks,
                message="é•¿ç‰‡æ®µå·²åˆ‡åˆ†",
            )

        return split_segments

    async def transcribe_only(
        self,
        audio_path: Path,
        language: str | None = None,
        prompt: str | None = None,
        on_progress: ProgressCallback | None = None,
    ) -> list[dict[str, Any]]:
        """åªè¿›è¡Œ Whisper è¯†åˆ«ï¼Œè¿”å›æ­Œè¯ç‰‡æ®µåˆ—è¡¨ï¼ˆä¸è¿›è¡Œè§†é¢‘åŒ¹é…ï¼‰ã€‚

        è¿”å›æ ¼å¼: [{"text": "æ­Œè¯", "start": å¼€å§‹ç§’, "end": ç»“æŸç§’}, ...]
        """

        async def report_progress(progress: float) -> None:
            if on_progress:
                await on_progress(progress)

        await report_progress(5.0)  # 5%: å¼€å§‹å¤„ç†éŸ³é¢‘
        audio_duration_ms = self._get_audio_duration(audio_path)
        self._logger.info(
            "timeline_builder.audio_info", path=str(audio_path), duration_ms=audio_duration_ms
        )
        await report_progress(20.0)  # 20%: å¼€å§‹ Whisper è¯†åˆ«

        raw_segments = await transcribe_with_timestamps(
            audio_path, language=language, prompt=prompt
        )
        segments = [dict(segment) for segment in raw_segments]

        await report_progress(80.0)  # 80%: Whisper è¯†åˆ«å®Œæˆ

        # åˆ†å‰²é•¿ç‰‡æ®µ
        segments = self._explode_segments(segments)

        await report_progress(100.0)  # 100%: å®Œæˆ
        return segments

    async def match_videos_for_lines(
        self,
        lines: list[dict[str, Any]],
        audio_duration_ms: int = 0,
        beats: BeatAnalysisResult | None = None,
        music_onsets: OnsetResult | None = None,
        on_progress: ProgressCallback | None = None,
    ) -> TimelineResult:
        """å¯¹å·²ç¡®è®¤çš„æ­Œè¯è¡Œè¿›è¡Œè§†é¢‘åŒ¹é…ã€‚

        Args:
            lines: æ­Œè¯è¡Œåˆ—è¡¨ï¼Œæ ¼å¼ [{"text": "...", "start_ms": int, "end_ms": int}, ...]
            audio_duration_ms: éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œç”¨äºå¡«å……å°¾éƒ¨
            beats: éŸ³é¢‘èŠ‚æ‹åˆ†æç»“æœï¼ˆç”¨äº action æ¨¡å¼å¡ç‚¹ï¼‰
            music_onsets: éŸ³ä¹é¼“ç‚¹æ£€æµ‹ç»“æœï¼ˆç”¨äº onset æ¨¡å¼å¡ç‚¹ï¼Œç±»ä¼¼å‰ªæ˜ ï¼‰
            on_progress: è¿›åº¦å›è°ƒ
        """
        self._candidate_cache.clear()
        self._used_segments.clear()

        async def report_progress(progress: float) -> None:
            if on_progress:
                await on_progress(progress)

        await report_progress(5.0)

        # è½¬æ¢ä¸ºå†…éƒ¨ segments æ ¼å¼
        segments: list[dict[str, Any]] = []
        for line in lines:
            segments.append(
                {
                    "text": line["text"],
                    "start": line["start_ms"] / 1000.0,
                    "end": line["end_ms"] / 1000.0,
                }
            )

        # æ ‡è®°éæ­Œè¯å†…å®¹
        for seg in segments:
            text = str(seg.get("text", "")).strip()
            start = float(seg.get("start", 0))
            end = float(seg.get("end", 0))
            duration_s = end - start

            if self._is_non_lyric_text(text):
                if duration_s < 10.0:
                    seg["is_non_lyric"] = True
                else:
                    seg["is_non_lyric"] = False
                    seg["search_prompt"] = "cinematic music video intro, atmospheric, slow motion"

        # åˆ‡åˆ†é•¿ç‰‡æ®µ
        segments = self._split_by_duration(segments, max_duration=12.0)
        segments.sort(key=lambda x: float(x.get("start", 0)))

        # è¿›è¡Œè§†é¢‘åŒ¹é…ï¼ˆå¤ç”¨ build æ–¹æ³•çš„åŒ¹é…é€»è¾‘ï¼‰
        timeline = TimelineResult()
        cursor_ms = 0
        total_segments = len(segments)

        for seg_idx, seg in enumerate(segments):
            if total_segments > 0:
                match_progress = 10.0 + (seg_idx / total_segments) * 85.0
                await report_progress(match_progress)

            raw_text = str(seg.get("text", ""))
            text = raw_text.strip().strip("'\"")
            if not text:
                continue

            start_ms = int(float(seg.get("start", 0)) * 1000)
            end_ms = int(float(seg.get("end", 0)) * 1000)

            # ğŸµ ç®€åŒ–ç‰ˆå¡ç‚¹ï¼šå°†ç”»é¢åˆ‡æ¢ç‚¹å¯¹é½åˆ°æœ€è¿‘çš„èŠ‚æ‹
            if beats and self._settings.beat_sync_enabled:
                aligned_start, aligned_end = self._align_start_to_beat(
                    start_ms, end_ms, beats, prev_end_ms=cursor_ms
                )
                if aligned_start != start_ms:
                    self._logger.info(
                        "timeline_builder.cut_aligned_to_beat",
                        text=text[:20],
                        original_start=start_ms,
                        aligned_start=aligned_start,
                        offset_ms=aligned_start - start_ms,
                    )
                    start_ms = aligned_start
                    end_ms = aligned_end

            # é—´éš™å¤„ç†
            if cursor_ms > 0 and start_ms > cursor_ms:
                gap = start_ms - cursor_ms
                if gap > 2000:
                    gap_prompt = (
                        "atmospheric music video, cinematic scenes, instrumental, no lyrics"
                    )
                    gap_candidates = await self._get_candidates(gap_prompt, limit=20)
                    normalized_gap = self._normalize_candidates(gap_candidates, cursor_ms, start_ms)
                    selected_gap = self._select_diverse_candidates(normalized_gap, limit=5)
                    if not selected_gap:
                        # éšæœºé€‰æ‹©ä¸€ä¸ªæœªä½¿ç”¨çš„ç‰‡æ®µ
                        gap_duration = start_ms - cursor_ms
                        random_gap = await self._get_random_unused_segment(
                            gap_duration, cursor_ms, start_ms
                        )
                        if random_gap:
                            selected_gap = [random_gap]
                    for candidate in selected_gap:
                        segment_key = (
                            str(candidate.get("source_video_id")),
                            int(candidate.get("start_time_ms", 0)),
                            int(candidate.get("end_time_ms", 0)),
                        )
                        self._used_segments[segment_key] = (
                            self._used_segments.get(segment_key, 0) + 1
                        )
                    timeline.lines.append(
                        TimelineLine(
                            text="(Instrumental)",
                            start_ms=cursor_ms,
                            end_ms=start_ms,
                            candidates=selected_gap,
                        )
                    )
                else:
                    start_ms = cursor_ms

            # å¤„ç†å½“å‰ç‰‡æ®µ
            if seg.get("is_non_lyric", False):
                candidates = []
            else:
                search_query = seg.get("search_prompt", text)
                candidates = await self._get_candidates(search_query, limit=20)

            normalized = self._normalize_candidates(candidates, start_ms, end_ms)

            # åº”ç”¨å¡ç‚¹è¯„åˆ†
            # æ³¨æ„ï¼šonset æ¨¡å¼çš„é¼“ç‚¹åˆ†æç§»åˆ°æ¸²æŸ“é˜¶æ®µï¼Œé¿å…åŒ¹é…æ—¶åˆ†æå¤šä¸ªå€™é€‰å¯¼è‡´å¤ªæ…¢
            beat_sync_mode = self._settings.beat_sync_mode if self._settings.beat_sync_enabled else None

            if beat_sync_mode == "action" and beats and beat_aligner.should_apply_beat_sync(beats):
                # åŠ¨ä½œé«˜å…‰å¯¹é½æ¨¡å¼ï¼ˆæ—§æ¨¡å¼ï¼Œåœ¨åŒ¹é…é˜¶æ®µè®¡ç®—ï¼‰
                selected_candidates = await self._select_candidates_with_beat_sync(
                    normalized, limit=5, lyric_start_ms=start_ms, beats=beats
                )
            else:
                # onset æ¨¡å¼æˆ–æ— å¡ç‚¹ï¼šåªæŒ‰ TwelveLabs è¯„åˆ†é€‰æ‹©ï¼Œé¼“ç‚¹åˆ†æåœ¨æ¸²æŸ“æ—¶å®æ—¶è¿›è¡Œ
                selected_candidates = self._select_diverse_candidates(normalized, limit=5)

            # å¦‚æœæ‰€æœ‰å€™é€‰éƒ½è¢«å»é‡æ‹’ç»ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªæœªä½¿ç”¨çš„ç‰‡æ®µ
            if not selected_candidates:
                lyric_duration_ms = end_ms - start_ms
                random_segment = await self._get_random_unused_segment(
                    lyric_duration_ms, start_ms, end_ms
                )
                if random_segment:
                    selected_candidates = [random_segment]

            for candidate in selected_candidates:
                segment_key = (
                    str(candidate.get("source_video_id")),
                    int(candidate.get("start_time_ms", 0)),
                    int(candidate.get("end_time_ms", 0)),
                )
                self._used_segments[segment_key] = self._used_segments.get(segment_key, 0) + 1

            timeline.lines.append(
                TimelineLine(
                    text=text,
                    start_ms=start_ms,
                    end_ms=end_ms,
                    candidates=selected_candidates,
                )
            )
            cursor_ms = max(cursor_ms, end_ms)

        # å°¾éƒ¨å¡«å……
        if audio_duration_ms > cursor_ms + 1000:
            gap_start = cursor_ms
            gap_end = audio_duration_ms
            outro_prompt = "ending music video, fade out, cinematic, atmospheric"
            outro_candidates = await self._get_candidates(outro_prompt, limit=20)
            normalized_outro = self._normalize_candidates(outro_candidates, gap_start, gap_end)
            selected_outro = self._select_diverse_candidates(normalized_outro, limit=5)
            if not selected_outro:
                # éšæœºé€‰æ‹©ä¸€ä¸ªæœªä½¿ç”¨çš„ç‰‡æ®µ
                outro_duration = gap_end - gap_start
                random_outro = await self._get_random_unused_segment(
                    outro_duration, gap_start, gap_end
                )
                if random_outro:
                    selected_outro = [random_outro]
            timeline.lines.append(
                TimelineLine(
                    text="(Outro)", start_ms=gap_start, end_ms=gap_end, candidates=selected_outro
                )
            )

        await report_progress(100.0)
        return timeline

    async def build(
        self,
        audio_path: Path | None,
        lyrics_text: Optional[str],
        language: str | None = None,
        prompt: str | None = None,
        on_progress: ProgressCallback | None = None,
    ) -> TimelineResult:
        """å®Œæ•´æ„å»ºæµç¨‹ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰ï¼šWhisper è¯†åˆ« + è§†é¢‘åŒ¹é…ã€‚"""
        self._candidate_cache.clear()
        self._used_segments.clear()  # é‡ç½®å·²ä½¿ç”¨ç‰‡æ®µè¿½è¸ª
        segments: list[dict[str, Any]] = []
        audio_duration_ms = 0

        async def report_progress(progress: float) -> None:
            if on_progress:
                await on_progress(progress)

        if audio_path:
            await report_progress(5.0)  # 5%: å¼€å§‹å¤„ç†éŸ³é¢‘
            audio_duration_ms = self._get_audio_duration(audio_path)
            self._logger.info(
                "timeline_builder.audio_info", path=str(audio_path), duration_ms=audio_duration_ms
            )
            await report_progress(10.0)  # 10%: å¼€å§‹ Whisper è¯†åˆ«
            raw_segments = await transcribe_with_timestamps(
                audio_path, language=language, prompt=prompt
            )
            segments = [dict(segment) for segment in raw_segments]
            await report_progress(30.0)  # 30%: Whisper è¯†åˆ«å®Œæˆ
        elif lyrics_text:
            for idx, line in enumerate(lyrics_text.splitlines()):
                stripped = line.strip()
                if not stripped:
                    continue
                segments.append({"text": stripped, "start": float(idx), "end": float(idx + 1)})
        else:
            raise ValueError("å¿…é¡»æä¾›éŸ³é¢‘æˆ–æ­Œè¯")

        segments = self._explode_segments(segments)

        # æ ‡è®°éæ­Œè¯å†…å®¹ï¼ˆä½œè¯ã€ä½œæ›²ç­‰ creditsï¼‰
        # ç­–ç•¥æ›´æ–°ï¼š
        # 1. çŸ­çš„ credits (< 10s) -> æ ‡è®°ä¸º non-lyricï¼Œä½¿ç”¨ fallback
        # 2. é•¿çš„ credits (>= 10s) -> è§†ä¸º Intro/Interludeï¼Œæ”¹å†™ text è¿›è¡Œæœç´¢
        non_lyric_count = 0
        for seg in segments:
            text = str(seg.get("text", "")).strip()
            start = float(seg.get("start", 0))
            end = float(seg.get("end", 0))
            duration_s = end - start

            if self._is_non_lyric_text(text):
                if duration_s < 10.0:
                    seg["is_non_lyric"] = True
                    non_lyric_count += 1
                    self._logger.info(
                        "timeline_builder.mark_non_lyric",
                        text=text,
                        duration_s=round(duration_s, 2),
                        message="çŸ­ Credit ä¿¡æ¯ï¼Œæ ‡è®°ä¸ºéæ­Œè¯ (Fallback)",
                    )
                else:
                    # é•¿ç‰‡æ®µï¼Œå³ä½¿åŒ…å« Credit ä¹Ÿä¸åº”è¯¥ç”¨é»‘å± Fallback
                    # æ”¹å†™ä¸ºé€šç”¨ Intro Prompt
                    seg["is_non_lyric"] = False
                    seg["search_prompt"] = "cinematic music video intro, atmospheric, slow motion"
                    self._logger.info(
                        "timeline_builder.convert_long_credit",
                        text=text,
                        duration_s=round(duration_s, 2),
                        message="é•¿ Credit ç‰‡æ®µï¼Œè½¬æ¢ä¸º Intro æœç´¢",
                    )

        if non_lyric_count > 0:
            self._logger.info(
                "timeline_builder.non_lyric_summary",
                total_count=len(segments),
                non_lyric_count=non_lyric_count,
                lyric_count=len(segments) - non_lyric_count,
                message=f"å‘ç° {non_lyric_count} ä¸ªçŸ­éæ­Œè¯ç‰‡æ®µ",
            )

        # åœ¨æ’åºå‰è¿›è¡Œæ—¶é•¿åˆ‡åˆ†
        # è¿™ä¼šå°† 30s çš„ Intro åˆ‡åˆ†ä¸º 3 ä¸ª 10s çš„ç‰‡æ®µï¼Œæ¯ä¸ªéƒ½ä¼šè¿›è¡Œç‹¬ç«‹çš„è§†é¢‘æœç´¢
        segments = self._split_by_duration(segments, max_duration=12.0)

        # æŒ‰å¼€å§‹æ—¶é—´æ’åºï¼Œç¡®ä¿æ—¶é—´çº¿è¿ç»­æ€§
        segments.sort(key=lambda x: float(x.get("start", 0)))

        timeline = TimelineResult()
        cursor_ms = 0
        total_segments = len(segments)

        for seg_idx, seg in enumerate(segments):
            # æ›´æ–°è¿›åº¦: 30% - 95% å¯¹åº”è§†é¢‘åŒ¹é…é˜¶æ®µ
            if total_segments > 0:
                match_progress = 30.0 + (seg_idx / total_segments) * 65.0
                await report_progress(match_progress)
            raw_text = str(seg.get("text", ""))
            text = raw_text.strip().strip("'\"")
            if not text:
                continue
            start_value = seg.get("start", 0)
            end_value = seg.get("end")
            start_ms = int(float(start_value) * 1000)
            if end_value is None:
                end_ms = start_ms + 1000
            else:
                end_ms = int(float(end_value) * 1000)

            # ğŸµ é—´éš™å¤„ç†ç­–ç•¥ (Gap Handling Strategy)
            # ç›®æ ‡ï¼šç¡®ä¿è§†é¢‘æ—¶é—´çº¿è¿ç»­ï¼Œæ— é»‘å±ï¼Œæ— è·³è·ƒ
            if cursor_ms > 0:  # åªæœ‰éç¬¬ä¸€å¥æ‰éœ€è¦å¤„ç†é—´éš™ï¼ˆç¬¬ä¸€å¥å‰é¢æ˜¯0ï¼‰
                if start_ms > cursor_ms:
                    gap = start_ms - cursor_ms

                    # ç­–ç•¥ 1: å¤§é—´éš™ -> æ’å…¥é—´å¥ç‰‡æ®µ
                    if gap > 2000:
                        self._logger.info(
                            "timeline_builder.fill_large_gap",
                            gap_start=cursor_ms,
                            gap_end=start_ms,
                            duration=gap,
                            message="å‘ç°å¤§é—´éš™ï¼Œæ’å…¥çº¯éŸ³ä¹ç”»é¢",
                        )

                        # æœç´¢çº¯éŸ³ä¹ç”»é¢
                        gap_prompt = (
                            "atmospheric music video, cinematic scenes, instrumental, no lyrics"
                        )
                        gap_candidates = await self._get_candidates(gap_prompt, limit=20)
                        normalized_gap = self._normalize_candidates(
                            gap_candidates, cursor_ms, start_ms
                        )
                        selected_gap = self._select_diverse_candidates(normalized_gap, limit=5)

                        # å…œåº•ï¼šéšæœºé€‰æ‹©æœªä½¿ç”¨çš„ç‰‡æ®µ
                        if not selected_gap:
                            gap_duration = start_ms - cursor_ms
                            random_gap = await self._get_random_unused_segment(
                                gap_duration, cursor_ms, start_ms
                            )
                            if random_gap:
                                selected_gap = [random_gap]

                        # æ ‡è®°å·²ä½¿ç”¨
                        for candidate in selected_gap:
                            segment_key = (
                                str(candidate.get("source_video_id")),
                                int(candidate.get("start_time_ms", 0)),
                                int(candidate.get("end_time_ms", 0)),
                            )
                            self._used_segments[segment_key] = (
                                self._used_segments.get(segment_key, 0) + 1
                            )

                        timeline.lines.append(
                            TimelineLine(
                                text="(Instrumental)",
                                start_ms=cursor_ms,
                                end_ms=start_ms,
                                candidates=selected_gap,
                            )
                        )

                    # ç­–ç•¥ 2: å°é—´éš™ -> å¸æ”¶ï¼ˆå‘å‰å»¶ä¼¸å½“å‰ç‰‡æ®µï¼‰
                    else:
                        self._logger.info(
                            "timeline_builder.absorb_small_gap",
                            original_start=start_ms,
                            new_start=cursor_ms,
                            gap_absorbed=gap,
                            message="å¸æ”¶å¾®å°é—´éš™ï¼Œå‘å‰å»¶ä¼¸å½“å‰ç‰‡æ®µ",
                        )
                        start_ms = cursor_ms  # ä¿®æ”¹å½“å‰ç‰‡æ®µçš„å¼€å§‹æ—¶é—´

            # å¤„ç†å½“å‰ç‰‡æ®µ
            if seg.get("is_non_lyric", False):
                # çŸ­ Credit -> Fallback
                candidates = []
            else:
                # ä¼˜å…ˆä½¿ç”¨ search_prompt (é’ˆå¯¹ Long Credit/Intro)
                search_query = seg.get("search_prompt", text)
                candidates = await self._get_candidates(search_query, limit=20)

            normalized = self._normalize_candidates(candidates, start_ms, end_ms)

            # é€‰æ‹©æœªä½¿ç”¨æˆ–ä½¿ç”¨æ¬¡æ•°æœ€å°‘çš„ç‰‡æ®µ
            selected_candidates = self._select_diverse_candidates(normalized, limit=5)

            # æ ‡è®°æ‰€æœ‰å€™é€‰ç‰‡æ®µä¸ºå·²ä½¿ç”¨ï¼ˆé˜²æ­¢åç»­å¥å­é‡å¤ä½¿ç”¨ï¼‰
            for candidate in selected_candidates:
                segment_key = (
                    str(candidate.get("source_video_id")),
                    int(candidate.get("start_time_ms", 0)),
                    int(candidate.get("end_time_ms", 0)),
                )
                self._used_segments[segment_key] = self._used_segments.get(segment_key, 0) + 1

            timeline.lines.append(
                TimelineLine(
                    text=text,
                    start_ms=start_ms,
                    end_ms=end_ms,
                    candidates=selected_candidates,
                )
            )
            cursor_ms = max(cursor_ms, end_ms)

        # ğŸµ å°¾éƒ¨å¡«å……é€»è¾‘ (Tail Gap Filling)
        self._logger.info(
            "timeline_builder.check_tail_gap",
            audio_duration_ms=audio_duration_ms,
            cursor_ms=cursor_ms,
            gap=audio_duration_ms - cursor_ms,
            threshold=1000,
            should_fill=audio_duration_ms > cursor_ms + 1000,
        )

        if audio_duration_ms > cursor_ms + 1000:
            gap_start = cursor_ms
            gap_end = audio_duration_ms
            self._logger.info(
                "timeline_builder.fill_tail_gap",
                gap_start=gap_start,
                gap_end=gap_end,
                duration=gap_end - gap_start,
                message="å¡«å……å°¾éƒ¨ç©ºéš™",
            )

            outro_prompt = "ending music video, fade out, cinematic, atmospheric"
            outro_candidates = await self._get_candidates(outro_prompt, limit=20)
            normalized_outro = self._normalize_candidates(outro_candidates, gap_start, gap_end)
            selected_outro = self._select_diverse_candidates(normalized_outro, limit=5)

            # å¦‚æœå› ä¸ºé‡å ç­‰åŸå› æ²¡æœ‰é€‰åˆ°å€™é€‰ï¼Œå¼ºåˆ¶ä½¿ç”¨ fallback
            if not selected_outro:
                # éšæœºé€‰æ‹©ä¸€ä¸ªæœªä½¿ç”¨çš„ç‰‡æ®µ
                outro_duration = gap_end - gap_start
                random_segment = await self._get_random_unused_segment(
                    outro_duration, gap_start, gap_end
                )
                if random_segment:
                    selected_outro = [random_segment]
                else:
                    self._logger.warning(
                        "timeline_builder.outro_no_segment",
                        gap_start=gap_start,
                        gap_end=gap_end,
                        message="Outro æ— æ³•æ‰¾åˆ°æœªä½¿ç”¨çš„ç‰‡æ®µï¼Œè·³è¿‡",
                    )

            timeline.lines.append(
                TimelineLine(
                    text="(Outro)", start_ms=gap_start, end_ms=gap_end, candidates=selected_outro
                )
            )

        await report_progress(100.0)  # 100%: æ—¶é—´çº¿ç”Ÿæˆå®Œæˆ
        return timeline

    def _normalize_candidates(
        self, raw_candidates: list[dict[str, int | float | str]], start_ms: int, end_ms: int
    ) -> list[dict[str, int | float | str]]:
        """
        è§„èŒƒåŒ–å€™é€‰è§†é¢‘ç‰‡æ®µï¼Œè¿‡æ»¤æ‰æ—¶é•¿ä¸è¶³çš„å€™é€‰ã€‚

        è¿‡æ»¤ç­–ç•¥ï¼š
        - è§†é¢‘ç‰‡æ®µæ—¶é•¿å¿…é¡» >= æ­Œè¯æ—¶é•¿ï¼Œå¦åˆ™ä¸¢å¼ƒ
        - ç¦æ­¢å¾ªç¯æ’­æ”¾ï¼Œç¡®ä¿ç”»é¢è¿è´¯æ€§
        """
        lyric_duration_ms = end_ms - start_ms
        lyric_duration_s = lyric_duration_ms / 1000.0

        def _candidate_defaults(
            candidate: dict[str, int | float | str],
        ) -> dict[str, int | float | str] | None:
            api_start = int(candidate.get("start", start_ms))
            api_end = int(candidate.get("end", end_ms))
            lyric_duration = end_ms - start_ms

            # æ£€æŸ¥è§†é¢‘ç‰‡æ®µæ—¶é•¿æ˜¯å¦è¶³å¤Ÿ
            api_duration_ms = api_end - api_start
            api_duration_s = api_duration_ms / 1000.0

            # ä¸¥æ ¼è¿‡æ»¤ï¼šè§†é¢‘æ—¶é•¿å¿…é¡» >= æ­Œè¯æ—¶é•¿ï¼Œå¦åˆ™ä¸¢å¼ƒ
            if api_duration_ms < lyric_duration_ms:
                self._logger.debug(
                    "timeline_builder.duration_insufficient",
                    video_id=candidate.get("video_id"),
                    lyric_duration_s=round(lyric_duration_s, 2),
                    api_duration_s=round(api_duration_s, 2),
                    shortage_s=round(lyric_duration_s - api_duration_s, 2),
                    message="è§†é¢‘æ—¶é•¿ä¸è¶³ï¼Œä¸¢å¼ƒè¯¥å€™é€‰",
                )
                return None

            # ä» API è¿”å›ç‰‡æ®µçš„ä¸­é—´ä½ç½®æˆªå–ï¼Œä»¥è·å¾—æœ€åŒ¹é…çš„ç”»é¢
            api_duration = api_end - api_start
            api_middle = api_start + (api_duration // 2)

            # ä»ä¸­é—´ä½ç½®å‘å‰åç§»ä¸€åŠæ­Œè¯æ—¶é•¿ï¼Œä½¿æ­Œè¯æ—¶é•¿å±…ä¸­
            clip_start = api_middle - (lyric_duration // 2)
            clip_end = clip_start + lyric_duration

            # è¾¹ç•Œæ£€æŸ¥ï¼šç¡®ä¿ä¸è¶…å‡º API ç‰‡æ®µèŒƒå›´
            if clip_start < api_start:
                clip_start = api_start
                clip_end = clip_start + lyric_duration

            if clip_end > api_end:
                clip_end = api_end
                clip_start = clip_end - lyric_duration

            return {
                "id": str(uuid4()),
                "source_video_id": candidate["video_id"],  # å¿…é¡»æœ‰ video_id
                "start_time_ms": clip_start,
                "end_time_ms": clip_end,
                "score": candidate.get("score", 0.0),
                # ä¿ç•™åŸå§‹æ•°æ®ä¾›å‚è€ƒ
                "api_start_ms": api_start,
                "api_end_ms": api_end,
                "api_middle_ms": api_middle,
                "api_duration_ms": api_duration_ms,
                "lyric_start_ms": start_ms,
                "lyric_end_ms": end_ms,
                "lyric_duration_ms": lyric_duration_ms,
            }

        if raw_candidates:
            # å¤„ç†æ‰€æœ‰å€™é€‰ï¼Œè¿‡æ»¤æ‰ Noneï¼ˆæ—¶é•¿ä¸åŒ¹é…çš„ï¼‰
            normalized = []
            for c in raw_candidates:
                result = _candidate_defaults(c)
                if result is not None:
                    normalized.append(result)

            # å¦‚æœæ‰€æœ‰å€™é€‰éƒ½è¢«è¿‡æ»¤æ‰äº†ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼Œè®©è°ƒç”¨æ–¹ä½¿ç”¨éšæœºé€‰æ‹©
            if not normalized:
                self._logger.warning(
                    "timeline_builder.all_candidates_filtered",
                    lyric_duration_s=round(lyric_duration_s, 2),
                    original_count=len(raw_candidates),
                    message="æ‰€æœ‰å€™é€‰è§†é¢‘æ—¶é•¿éƒ½ä¸åŒ¹é…ï¼Œè¿”å›ç©ºåˆ—è¡¨å¾…éšæœºé€‰æ‹©",
                )
                return []

            return normalized

        # æ²¡æœ‰åŸå§‹å€™é€‰æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œè®©è°ƒç”¨æ–¹å†³å®šå¦‚ä½•å¤„ç†
        return []

    async def _get_random_unused_segment(
        self, lyric_duration_ms: int, start_ms: int, end_ms: int
    ) -> dict[str, Any] | None:
        """
        å½“æ‰€æœ‰å€™é€‰éƒ½è¢«å»é‡æ‹’ç»æ—¶ï¼Œä½¿ç”¨é€šç”¨æŸ¥è¯¢æœç´¢æœªä½¿ç”¨çš„ç‰‡æ®µã€‚

        ç­–ç•¥ï¼š
        1. å…ˆä»å·²ç¼“å­˜çš„å€™é€‰ä¸­æŸ¥æ‰¾æœªä½¿ç”¨çš„ç‰‡æ®µ
        2. å¦‚æœæ²¡æœ‰ï¼Œä½¿ç”¨é€šç”¨æŸ¥è¯¢è¯æœç´¢æ–°çš„ç‰‡æ®µ
        3. ç­›é€‰å‡ºæœªä½¿ç”¨ä¸”ä¸é‡å çš„ç‰‡æ®µ
        4. éšæœºé€‰æ‹©ä¸€ä¸ªè¿”å›
        """
        import random

        def is_segment_available(video_id: str, seg_start: int, seg_end: int) -> bool:
            """æ£€æŸ¥ç‰‡æ®µæ˜¯å¦å¯ç”¨ï¼ˆæœªä½¿ç”¨ä¸”ä¸ä¸å·²ä½¿ç”¨ç‰‡æ®µé‡å ï¼‰"""
            segment_key = (video_id, seg_start, seg_end)

            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            if self._used_segments.get(segment_key, 0) > 0:
                return False

            # æ£€æŸ¥é‡å 
            for used_key in self._used_segments.keys():
                used_video_id, used_start, used_end = used_key
                if used_video_id == video_id:
                    overlap = calculate_overlap_ratio(seg_start, seg_end, used_start, used_end)
                    if overlap > 0:
                        return False

            return True

        def try_extract_segment(candidate: dict[str, Any]) -> dict[str, Any] | None:
            """å°è¯•ä»å€™é€‰ä¸­æå–å¯ç”¨ç‰‡æ®µ"""
            video_id = candidate.get("video_id", "")
            # TwelveLabs å®¢æˆ·ç«¯è¿”å›çš„ start/end å·²ç»æ˜¯æ¯«ç§’
            api_start = int(candidate.get("start", 0))
            api_end = int(candidate.get("end", 0))
            api_duration_ms = api_end - api_start

            # æ£€æŸ¥æ—¶é•¿æ˜¯å¦è¶³å¤Ÿ
            if api_duration_ms < lyric_duration_ms:
                return None

            # è®¡ç®—è£å‰ªä½ç½®ï¼ˆä»ä¸­é—´æˆªå–ï¼‰
            api_duration = api_end - api_start
            api_middle = api_start + (api_duration // 2)
            clip_start = api_middle - (lyric_duration_ms // 2)
            clip_end = clip_start + lyric_duration_ms

            # è¾¹ç•Œæ£€æŸ¥
            if clip_start < api_start:
                clip_start = api_start
                clip_end = clip_start + lyric_duration_ms
            if clip_end > api_end:
                clip_end = api_end
                clip_start = clip_end - lyric_duration_ms

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨
            if not is_segment_available(video_id, clip_start, clip_end):
                return None

            return {
                "id": str(uuid4()),
                "source_video_id": video_id,
                "start_time_ms": clip_start,
                "end_time_ms": clip_end,
                "score": candidate.get("score", 0.0),
                "is_random_fill": True,
                "lyric_start_ms": start_ms,
                "lyric_end_ms": end_ms,
            }

        # ç­–ç•¥1ï¼šä»å·²ç¼“å­˜çš„å€™é€‰ä¸­æŸ¥æ‰¾
        available_from_cache = []
        for candidate in self._all_seen_candidates:
            result = try_extract_segment(candidate)
            if result:
                available_from_cache.append(result)

        if available_from_cache:
            selected = random.choice(available_from_cache)
            self._logger.info(
                "timeline_builder.random_fill_from_cache",
                video_id=selected["source_video_id"],
                start_ms=selected["start_time_ms"],
                end_ms=selected["end_time_ms"],
                cache_available=len(available_from_cache),
                message="ä»ç¼“å­˜ä¸­éšæœºé€‰æ‹©æœªä½¿ç”¨ç‰‡æ®µ",
            )
            return selected

        # ç­–ç•¥2ï¼šä½¿ç”¨é€šç”¨æŸ¥è¯¢æœç´¢æ–°çš„ç‰‡æ®µ
        query = self._generic_queries[self._generic_query_index % len(self._generic_queries)]
        self._generic_query_index += 1

        self._logger.info(
            "timeline_builder.random_fill_search",
            query=query,
            message="ä½¿ç”¨é€šç”¨æŸ¥è¯¢æœç´¢æ–°ç‰‡æ®µ",
        )

        new_candidates = await client.search_segments(query, limit=50)

        # å°†æ–°å€™é€‰åŠ å…¥ç¼“å­˜
        for c in new_candidates:
            if c not in self._all_seen_candidates:
                self._all_seen_candidates.append(c)

        # ä»æ–°å€™é€‰ä¸­æŸ¥æ‰¾å¯ç”¨ç‰‡æ®µ
        available_from_search = []
        for candidate in new_candidates:
            result = try_extract_segment(candidate)
            if result:
                available_from_search.append(result)

        if available_from_search:
            selected = random.choice(available_from_search)
            self._logger.info(
                "timeline_builder.random_fill_from_search",
                video_id=selected["source_video_id"],
                start_ms=selected["start_time_ms"],
                end_ms=selected["end_time_ms"],
                search_available=len(available_from_search),
                message="ä»é€šç”¨æœç´¢ä¸­éšæœºé€‰æ‹©æœªä½¿ç”¨ç‰‡æ®µ",
            )
            return selected

        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å› None
        self._logger.warning(
            "timeline_builder.no_available_segments",
            lyric_duration_ms=lyric_duration_ms,
            used_count=len(self._used_segments),
            cache_size=len(self._all_seen_candidates),
            message="æ— æ³•æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æœªä½¿ç”¨ç‰‡æ®µ",
        )
        return None

    async def _get_candidates(self, text: str, limit: int) -> list[dict[str, Any]]:
        """
        è·å–å€™é€‰ç‰‡æ®µï¼ŒåŸºäºåˆ†æ•°é˜ˆå€¼çš„æ™ºèƒ½æ”¹å†™ç­–ç•¥ï¼š

        1. åŸå§‹æŸ¥è¯¢ â†’ è·å–ç»“æœå’Œ top score
        2. score >= threshold (0.9) â†’ ç›´æ¥ä½¿ç”¨åŸå§‹ç»“æœï¼ˆç›´ç™½æ­Œè¯ï¼‰
        3. score < threshold â†’ å°è¯•æ”¹å†™ â†’ å¯¹æ¯”é€‰æ‹©æ›´å¥½çš„ç»“æœï¼ˆæŠ½è±¡æ­Œè¯ï¼‰
        4. æ”¹å†™ååˆ†æ•°æ›´é«˜ â†’ ä½¿ç”¨æ”¹å†™ç»“æœ
        5. æ”¹å†™ååˆ†æ•°æ›´ä½ â†’ ä½¿ç”¨åŸå§‹ç»“æœ
        """
        key = (text, limit)
        if key not in self._candidate_cache:
            candidates: list[dict[str, Any]] = []
            score_threshold = self._settings.query_rewrite_score_threshold

            # ç¬¬ä¸€æ­¥ï¼šç”¨åŸå§‹æ­Œè¯æœç´¢
            original_candidates = await client.search_segments(text, limit=limit)
            original_top_score = (
                float(original_candidates[0].get("score", 0.0))
                if original_candidates
                else 0.0
            )

            self._logger.info(
                "timeline_builder.original_search",
                query=text[:50],
                count=len(original_candidates),
                top_score=round(original_top_score, 3),
                threshold=score_threshold,
            )

            # ç¬¬äºŒæ­¥ï¼šæ ¹æ®åˆ†æ•°å†³å®šæ˜¯å¦æ”¹å†™
            if original_top_score >= score_threshold:
                # åˆ†æ•°è¶³å¤Ÿé«˜ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹ç»“æœï¼ˆç›´ç™½æ­Œè¯ï¼Œä¸éœ€è¦æ”¹å†™ï¼‰
                candidates = original_candidates
                self._logger.info(
                    "timeline_builder.skip_rewrite",
                    query=text[:30],
                    score=round(original_top_score, 3),
                    reason="score >= threshold, no rewrite needed",
                )
            elif self._rewriter._enabled:
                # åˆ†æ•°ä½äºé˜ˆå€¼ï¼Œä½¿ç”¨ DeepSeek æ”¹å†™ä¸€æ¬¡
                rewritten_query = await self._rewriter.rewrite(text)

                # å¦‚æœæ”¹å†™ç»“æœä¸åŸå§‹ç›¸åŒï¼Œä½¿ç”¨åŸå§‹ç»“æœ
                if rewritten_query == text:
                    self._logger.debug(
                        "timeline_builder.rewrite_identical",
                        original=text[:30],
                    )
                    candidates = original_candidates
                else:
                    # ç”¨æ”¹å†™åçš„æŸ¥è¯¢æœç´¢
                    rewritten_candidates = await client.search_segments(
                        rewritten_query, limit=limit
                    )
                    rewritten_top_score = (
                        float(rewritten_candidates[0].get("score", 0.0))
                        if rewritten_candidates
                        else 0.0
                    )

                    self._logger.info(
                        "timeline_builder.rewrite_search",
                        original=text[:30],
                        rewritten=rewritten_query[:50],
                        original_score=round(original_top_score, 3),
                        rewritten_score=round(rewritten_top_score, 3),
                    )

                    # é€‰æ‹©æ›´å¥½çš„ç»“æœ
                    if rewritten_top_score > original_top_score:
                        candidates = rewritten_candidates
                        self._logger.info(
                            "timeline_builder.rewrite_better",
                            original=text[:30],
                            rewritten=rewritten_query[:50],
                            score_improvement=round(rewritten_top_score - original_top_score, 3),
                        )
                    else:
                        candidates = original_candidates
                        self._logger.info(
                            "timeline_builder.rewrite_not_better",
                            original=text[:30],
                            rewritten=rewritten_query[:50],
                            reason="original score was better",
                        )

            else:
                # æ”¹å†™æœªå¯ç”¨ï¼Œä½¿ç”¨åŸå§‹ç»“æœ
                candidates = original_candidates

            self._candidate_cache[key] = candidates

            # å°†æ–°å€™é€‰åŠ å…¥å…¨å±€ç¼“å­˜ï¼Œç”¨äºéšæœºé€‰æ‹©
            for c in candidates:
                if c not in self._all_seen_candidates:
                    self._all_seen_candidates.append(c)

        candidates = [candidate.copy() for candidate in self._candidate_cache[key]]
        count = len(candidates)
        log_method = self._logger.warning if count == 0 else self._logger.info
        log_method(
            "timeline_builder.candidates",
            text_preview=text[:30],
            count=count,
            use_mock=self._use_mock_segments,
        )
        return candidates

    def _select_diverse_candidates(
        self, candidates: list[dict[str, int | float | str]], limit: int
    ) -> list[dict[str, int | float | str]]:
        """
        ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©å¤šæ ·åŒ–çš„ç‰‡æ®µï¼Œä¸¥æ ¼ç¡®ä¿æ¯ä¸ªç‰‡æ®µåªä½¿ç”¨ä¸€æ¬¡ã€‚

        **ä¸¥æ ¼ç­–ç•¥**ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚ï¼‰ï¼š
        1. å®Œå…¨ç¦æ­¢é‡å¤ä½¿ç”¨ï¼šusage_count > 0 çš„ç‰‡æ®µç›´æ¥å‰”é™¤
        2. å®Œå…¨ç¦æ­¢é‡å ï¼šä»»ä½•é‡å  > 0 çš„ç‰‡æ®µç›´æ¥å‰”é™¤
        3. å¦‚æœæ²¡æœ‰å¯ç”¨ç‰‡æ®µï¼Œè¿”å›ç©ºï¼ˆä½¿ç”¨ fallback è§†é¢‘ï¼‰
        4. æŒ‰è¯„åˆ†é™åºæ’åºé€‰æ‹©æœ€ä½³çš„æœªä½¿ç”¨ç‰‡æ®µ
        """
        if not candidates:
            return []

        # ä¸ºæ¯ä¸ªå€™é€‰ç‰‡æ®µæ£€æµ‹ä½¿ç”¨æ¬¡æ•°å’Œæ—¶é—´é‡å 
        valid_candidates: list[CandidateWithUsage] = []
        rejected_count = 0

        for candidate in candidates:
            video_id = str(candidate.get("source_video_id", ""))
            start_ms = int(candidate.get("start_time_ms", 0))
            end_ms = int(candidate.get("end_time_ms", 0))
            segment_key = (video_id, start_ms, end_ms)

            # ç­–ç•¥1ï¼šå®Œå…¨ç¦æ­¢é‡å¤ä½¿ç”¨ - æ£€æŸ¥ç²¾ç¡®åŒ¹é…
            usage_count = self._used_segments.get(segment_key, 0)
            if usage_count > 0:
                self._logger.info(
                    "timeline_builder.reject_reused",
                    video_id=video_id,
                    start_ms=start_ms,
                    end_ms=end_ms,
                    usage_count=usage_count,
                    message="ä¸¥æ ¼å»é‡ï¼šç‰‡æ®µå·²ä½¿ç”¨è¿‡ï¼Œç›´æ¥å‰”é™¤",
                )
                rejected_count += 1
                continue

            # ç­–ç•¥2ï¼šå®Œå…¨ç¦æ­¢é‡å  - æ£€æŸ¥ä¸æ‰€æœ‰å·²ä½¿ç”¨ç‰‡æ®µçš„é‡å 
            has_overlap = False
            for used_key in self._used_segments.keys():
                used_video_id, used_start, used_end = used_key
                if used_video_id == video_id:
                    overlap_ratio = calculate_overlap_ratio(start_ms, end_ms, used_start, used_end)
                    if overlap_ratio > 0:
                        has_overlap = True
                        self._logger.info(
                            "timeline_builder.reject_overlap",
                            video_id=video_id,
                            start_ms=start_ms,
                            end_ms=end_ms,
                            overlapping_with=used_key,
                            overlap_ratio=round(overlap_ratio, 3),
                            message="ä¸¥æ ¼å»é‡ï¼šç‰‡æ®µä¸å·²ä½¿ç”¨ç‰‡æ®µé‡å ï¼Œç›´æ¥å‰”é™¤",
                        )
                        rejected_count += 1
                        break

            if has_overlap:
                continue

            # é€šè¿‡æ‰€æœ‰æ£€æŸ¥ï¼ŒåŠ å…¥æœ‰æ•ˆå€™é€‰åˆ—è¡¨
            # ğŸ¬ ç”»é¢è¿è´¯æ€§ï¼šåŒæºè§†é¢‘åŠ åˆ†
            original_score = float(candidate.get("score", 0.0))
            continuity_bonus = 0.0
            if self._last_used_video_id and video_id == self._last_used_video_id:
                continuity_bonus = self._continuity_bonus
            adjusted_score = original_score + continuity_bonus

            valid_candidates.append(
                {
                    "candidate": candidate,
                    "usage_count": 0,  # è‚¯å®šæ˜¯ 0ï¼Œå› ä¸ºå·²ç»è¿‡æ»¤æ‰äº† > 0 çš„
                    "score": adjusted_score,
                    "original_score": original_score,
                    "continuity_bonus": continuity_bonus,
                    "video_id": video_id,
                }
            )

        # ç­–ç•¥4ï¼šæŒ‰è¯„åˆ†é™åºæ’åºé€‰æ‹©æœ€ä½³çš„ï¼ˆåŒ…å«è¿è´¯æ€§åŠ æˆï¼‰
        valid_candidates.sort(key=lambda x: -x["score"])

        # æå–å€™é€‰ç‰‡æ®µå¹¶é™åˆ¶æ•°é‡
        selected: list[dict[str, int | float | str]] = [
            item["candidate"] for item in valid_candidates[:limit]
        ]

        # ç­–ç•¥3ï¼šå¦‚æœæ²¡æœ‰å¯ç”¨ç‰‡æ®µï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼Œè®©è°ƒç”¨æ–¹ä½¿ç”¨éšæœºé€‰æ‹©
        if not selected:
            self._logger.warning(
                "timeline_builder.no_valid_candidates",
                total_candidates=len(candidates),
                rejected_count=rejected_count,
                message="ä¸¥æ ¼å»é‡ï¼šæ‰€æœ‰å€™é€‰éƒ½å·²ä½¿ç”¨æˆ–é‡å ï¼Œå°†éšæœºé€‰æ‹©æœªä½¿ç”¨ç‰‡æ®µ",
            )
            return []

        # è®°å½•é€‰ä¸­çš„ç‰‡æ®µè¯¦ç»†ä¿¡æ¯
        for idx, item in enumerate(valid_candidates[:limit]):
            candidate = item["candidate"]
            continuity_info = ""
            if item.get("continuity_bonus", 0) > 0:
                continuity_info = f" [è¿è´¯æ€§åŠ æˆ +{item['continuity_bonus']:.2f}]"
            self._logger.info(
                "timeline_builder.selected_clip",
                index=idx + 1,
                video_id=item.get("video_id"),
                start_ms=candidate.get("start_time_ms"),
                end_ms=candidate.get("end_time_ms"),
                duration_ms=candidate.get("end_time_ms", 0) - candidate.get("start_time_ms", 0),
                original_score=item.get("original_score"),
                adjusted_score=item.get("score"),
                continuity_bonus=item.get("continuity_bonus", 0),
                message=f"é€‰ä¸­ç‰‡æ®µ{continuity_info}",
            )

        # ğŸ¬ æ›´æ–°æœ€åä½¿ç”¨çš„è§†é¢‘IDï¼ˆç”¨äºè¿è´¯æ€§è¯„åˆ†ï¼‰
        if valid_candidates:
            self._last_used_video_id = valid_candidates[0].get("video_id")
            self._logger.debug(
                "timeline_builder.continuity_tracking",
                last_video_id=self._last_used_video_id,
            )

        self._logger.info(
            "timeline_builder.strict_deduplication_summary",
            total_candidates=len(candidates),
            valid_count=len(valid_candidates),
            rejected_count=rejected_count,
            selected_count=len(selected),
            last_video_id=self._last_used_video_id,
            message=f"ä¸¥æ ¼å»é‡ï¼šä»{len(candidates)}ä¸ªå€™é€‰ä¸­ç­›é€‰å‡º{len(valid_candidates)}ä¸ªæœ‰æ•ˆï¼Œé€‰æ‹©äº†{len(selected)}ä¸ª",
        )

        return selected

    async def _select_candidates_with_beat_sync(
        self,
        candidates: list[dict[str, int | float | str]],
        limit: int,
        lyric_start_ms: int,
        beats: BeatAnalysisResult,
    ) -> list[dict[str, int | float | str]]:
        """
        é€‰æ‹©å€™é€‰ç‰‡æ®µå¹¶åº”ç”¨å¡ç‚¹è¯„åˆ†ã€‚

        æµç¨‹:
        1. å…ˆç”¨ä¸¥æ ¼å»é‡ç­›é€‰æœ‰æ•ˆå€™é€‰
        2. è·å–æ¯ä¸ªå€™é€‰è§†é¢‘çš„åŠ¨ä½œæ¡£æ¡ˆ
        3. è®¡ç®—å¡ç‚¹å¯¹é½åˆ†æ•°
        4. æŒ‰ç»¼åˆè¯„åˆ†æ’åºé€‰æ‹©
        5. å­˜å‚¨ beat_sync_offset_ms ä¾›æ¸²æŸ“ä½¿ç”¨

        Args:
            candidates: å€™é€‰ç‰‡æ®µåˆ—è¡¨
            limit: é€‰æ‹©æ•°é‡é™åˆ¶
            lyric_start_ms: æ­Œè¯è¡Œèµ·å§‹æ—¶é—´
            beats: èŠ‚æ‹åˆ†æç»“æœ

        Returns:
            å¸¦æœ‰ beat_sync_offset_ms çš„å€™é€‰åˆ—è¡¨
        """
        if not candidates:
            return []

        # ç¬¬ä¸€æ­¥ï¼šåº”ç”¨ä¸¥æ ¼å»é‡è¿‡æ»¤
        valid_candidates: list[dict[str, Any]] = []
        rejected_count = 0

        for candidate in candidates:
            video_id = str(candidate.get("source_video_id", ""))
            start_ms = int(candidate.get("start_time_ms", 0))
            end_ms = int(candidate.get("end_time_ms", 0))
            segment_key = (video_id, start_ms, end_ms)

            # æ£€æŸ¥ç²¾ç¡®åŒ¹é…é‡å¤
            usage_count = self._used_segments.get(segment_key, 0)
            if usage_count > 0:
                rejected_count += 1
                continue

            # æ£€æŸ¥æ—¶é—´é‡å 
            has_overlap = False
            for used_key in self._used_segments.keys():
                used_video_id, used_start, used_end = used_key
                if used_video_id == video_id:
                    overlap_ratio = calculate_overlap_ratio(start_ms, end_ms, used_start, used_end)
                    if overlap_ratio > 0:
                        has_overlap = True
                        rejected_count += 1
                        break

            if has_overlap:
                continue

            valid_candidates.append(dict(candidate))

        if not valid_candidates:
            self._logger.warning(
                "timeline_builder.beat_sync_no_candidates",
                total=len(candidates),
                rejected=rejected_count,
                message="å¡ç‚¹é€‰æ‹©ï¼šæ‰€æœ‰å€™é€‰éƒ½è¢«è¿‡æ»¤",
            )
            return []

        # ç¬¬äºŒæ­¥ï¼šè·å–è§†é¢‘åŠ¨ä½œæ¡£æ¡ˆå¹¶è®¡ç®—å¡ç‚¹åˆ†æ•°
        scored_candidates: list[tuple[dict[str, Any], float, int]] = []

        for candidate in valid_candidates:
            video_id = str(candidate.get("source_video_id", ""))
            original_score = float(candidate.get("score", 0.0))

            # å°è¯•è·å–è§†é¢‘åŠ¨ä½œæ¡£æ¡ˆ
            video_profile = None
            try:
                video_profile = await action_detector.analyze_video(video_id)
            except Exception as exc:
                self._logger.debug(
                    "timeline_builder.action_detect_failed",
                    video_id=video_id,
                    error=str(exc),
                )

            # è®¡ç®—å¡ç‚¹å¯¹é½åˆ†æ•°
            alignment = beat_aligner.calculate_alignment_score(
                candidate=candidate,
                lyric_start_ms=lyric_start_ms,
                beats=beats,
                video_profile=video_profile,
            )

            # å­˜å‚¨å¡ç‚¹åç§»é‡ä¾›æ¸²æŸ“ä½¿ç”¨
            candidate["beat_sync_offset_ms"] = alignment.offset_ms
            candidate["beat_sync_score"] = alignment.score
            candidate["beat_sync_details"] = alignment.details

            scored_candidates.append((candidate, alignment.score, alignment.offset_ms))

            self._logger.debug(
                "timeline_builder.beat_sync_scored",
                video_id=video_id,
                original_score=round(original_score, 3),
                beat_sync_score=round(alignment.score, 3),
                offset_ms=alignment.offset_ms,
                has_action_profile=video_profile is not None,
            )

        # ç¬¬ä¸‰æ­¥ï¼šæŒ‰ç»¼åˆè¯„åˆ†é™åºæ’åº
        scored_candidates.sort(key=lambda x: -x[1])

        # é€‰æ‹© top N
        selected = [item[0] for item in scored_candidates[:limit]]

        if selected:
            self._logger.info(
                "timeline_builder.beat_sync_selected",
                total=len(candidates),
                valid=len(valid_candidates),
                selected=len(selected),
                top_score=round(scored_candidates[0][1], 3) if scored_candidates else 0,
                top_offset=scored_candidates[0][2] if scored_candidates else 0,
                message="å¡ç‚¹é€‰æ‹©å®Œæˆ",
            )

        return selected

    async def _select_candidates_with_onset_sync(
        self,
        candidates: list[dict[str, Any]],
        limit: int,
        lyric_start_ms: int,
        lyric_end_ms: int,
        music_onsets: OnsetResult,
    ) -> list[dict[str, Any]]:
        """åŸºäºé¼“ç‚¹å¯¹é½é€‰æ‹©å€™é€‰è§†é¢‘ï¼ˆç±»ä¼¼å‰ªæ˜ è‡ªåŠ¨å¡ç‚¹ï¼‰ã€‚

        æ ¸å¿ƒé€»è¾‘ï¼š
        1. è·å–æ­Œè¯æ—¶é—´æ®µå†…çš„éŸ³ä¹é¼“ç‚¹
        2. ä»è§†é¢‘éŸ³é¢‘ä¸­æå–é¼“ç‚¹
        3. è®¡ç®—æœ€ä½³åç§»ä½¿ä¸¤è€…é¼“ç‚¹å¯¹é½
        4. æŒ‰å¯¹é½åˆ†æ•°æ’åºé€‰æ‹©å€™é€‰

        Args:
            candidates: å€™é€‰åˆ—è¡¨
            limit: é€‰æ‹©æ•°é‡
            lyric_start_ms: æ­Œè¯å¼€å§‹æ—¶é—´
            lyric_end_ms: æ­Œè¯ç»“æŸæ—¶é—´
            music_onsets: æ•´é¦–æ­Œæ›²çš„é¼“ç‚¹æ£€æµ‹ç»“æœ
        """
        if not candidates:
            return []

        # ç¬¬ä¸€æ­¥ï¼šåº”ç”¨å»é‡è¿‡æ»¤ï¼ˆä¸ beat_sync ç›¸åŒï¼‰
        valid_candidates: list[dict[str, Any]] = []
        rejected_count = 0

        for candidate in candidates:
            video_id = str(candidate.get("source_video_id", ""))
            start_ms = int(candidate.get("start_time_ms", 0))
            end_ms = int(candidate.get("end_time_ms", 0))
            segment_key = (video_id, start_ms, end_ms)

            usage_count = self._used_segments.get(segment_key, 0)
            if usage_count > 0:
                rejected_count += 1
                continue

            has_overlap = False
            for used_key in self._used_segments.keys():
                used_video_id, used_start, used_end = used_key
                if used_video_id == video_id:
                    overlap_ratio = calculate_overlap_ratio(start_ms, end_ms, used_start, used_end)
                    if overlap_ratio > 0:
                        has_overlap = True
                        rejected_count += 1
                        break

            if has_overlap:
                continue

            valid_candidates.append(dict(candidate))

        if not valid_candidates:
            self._logger.warning(
                "timeline_builder.onset_sync_no_candidates",
                total=len(candidates),
                rejected=rejected_count,
            )
            return []

        # ç¬¬äºŒæ­¥ï¼šåªå¯¹ Top 3 å€™é€‰è®¡ç®—é¼“ç‚¹å¯¹é½ï¼ˆé¿å…åˆ†æå…¨éƒ¨å€™é€‰å¯¼è‡´å¤ªæ…¢ï¼‰
        # å…ˆæŒ‰ TwelveLabs åŸå§‹è¯„åˆ†æ’åºï¼Œå–å‰ 3 ä¸ª
        valid_candidates.sort(key=lambda x: -float(x.get("score", 0.0)))
        top_candidates = valid_candidates[:3]

        self._logger.info(
            "timeline_builder.onset_sync_analyzing",
            total_valid=len(valid_candidates),
            analyzing=len(top_candidates),
            message=f"åªåˆ†æå‰ {len(top_candidates)} ä¸ªå€™é€‰çš„é¼“ç‚¹",
        )

        scored_candidates: list[tuple[dict[str, Any], float, int]] = []

        for candidate in top_candidates:
            video_id = str(candidate.get("source_video_id", ""))
            original_score = float(candidate.get("score", 0.0))

            # è·å–è§†é¢‘æµ URL ç”¨äºæå–éŸ³é¢‘
            video_stream_url = None
            try:
                video_stream_url = video_fetcher._get_stream_url(video_id)
            except Exception as exc:
                self._logger.debug(
                    "timeline_builder.get_stream_url_failed",
                    video_id=video_id,
                    error=str(exc),
                )

            # è®¡ç®—é¼“ç‚¹å¯¹é½åˆ†æ•°
            alignment = await beat_aligner.calculate_onset_alignment(
                candidate=candidate,
                lyric_start_ms=lyric_start_ms,
                lyric_end_ms=lyric_end_ms,
                music_onsets=music_onsets,
                video_stream_url=video_stream_url,
            )

            # å­˜å‚¨å¯¹é½ä¿¡æ¯
            candidate["beat_sync_offset_ms"] = alignment.offset_ms
            candidate["beat_sync_score"] = alignment.score
            candidate["beat_sync_details"] = alignment.details

            scored_candidates.append((candidate, alignment.score, alignment.offset_ms))

            self._logger.debug(
                "timeline_builder.onset_sync_scored",
                video_id=video_id,
                original_score=round(original_score, 3),
                onset_sync_score=round(alignment.score, 3),
                offset_ms=alignment.offset_ms,
            )

        # ç¬¬ä¸‰æ­¥ï¼šæŒ‰å¯¹é½åˆ†æ•°æ’åº
        scored_candidates.sort(key=lambda x: -x[1])

        # é€‰æ‹© top N
        selected = [item[0] for item in scored_candidates[:limit]]

        if selected:
            self._logger.info(
                "timeline_builder.onset_sync_selected",
                total=len(candidates),
                valid=len(valid_candidates),
                selected=len(selected),
                top_score=round(scored_candidates[0][1], 3) if scored_candidates else 0,
                top_offset=scored_candidates[0][2] if scored_candidates else 0,
                message="é¼“ç‚¹å¡ç‚¹é€‰æ‹©å®Œæˆ",
            )

        return selected

    def _explode_segments(self, segments: list[dict[str, Any]]) -> list[dict[str, Any]]:
        exploded: list[dict[str, Any]] = []
        for seg in segments:
            text = str(seg.get("text", "")).strip()
            if not text:
                continue
            pieces = [
                piece.strip()
                for piece in self._split_pattern.split(text)
                if piece and piece.strip()
            ]
            if len(pieces) <= 1:
                exploded.append(seg)
                continue
            start = float(seg.get("start", 0.0))
            end = float(seg.get("end", start + 1.0))
            if end <= start:
                end = start + 1.0
            duration = end - start
            total_chars = sum(len(piece) for piece in pieces) or len(pieces)
            cursor = start
            for idx, piece in enumerate(pieces):
                ratio = len(piece) / total_chars if total_chars else 1.0 / len(pieces)
                chunk_duration = duration * ratio
                chunk_end = end if idx == len(pieces) - 1 else cursor + chunk_duration
                exploded.append(
                    {
                        **seg,
                        "text": piece,
                        "start": cursor,
                        "end": chunk_end,
                    }
                )
                cursor = chunk_end
        return exploded
